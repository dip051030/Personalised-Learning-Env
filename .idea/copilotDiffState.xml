<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/logis/logical_functions.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/logis/logical_functions.py" />
              <option name="originalContent" value="import logging&#10;import chromadb&#10;&#10;logging.basicConfig(&#10;    level=logging.INFO,&#10;    format='%(asctime)s %(levelname)s [%(filename)s:%(lineno)d] %(levelname)s %(message)s',&#10;    datefmt='%Y-%m-%d %H:%M:%S'&#10;)&#10;&#10;from schemas import LearningResource, ResourceSubject, LearningState, ContentResponse, FeedBack, ContentType&#10;from db.vector_db import build_chroma_db_collection, save_scraped_data_to_vdb&#10;from sentence_transformers import SentenceTransformer&#10;&#10;&#10;def search_both_collections(state : LearningState,&#10;                            vdb_path=&quot;./local VDB/chromadb&quot;,&#10;                            lessons_collection=&quot;lessons&quot;,&#10;                            scraped_collection=&quot;scraped_data&quot;,&#10;                            n_results=1):&#10;    &quot;&quot;&quot;&#10;    Search both the lessons and scraped_data collections for the most similar items to the query.&#10;    Returns results from both collections.&#10;    &quot;&quot;&quot;&#10;    try:&#10;        if state.current_resource is None:&#10;            return None&#10;&#10;&#10;        build_chroma_db_collection()&#10;        save_scraped_data_to_vdb()&#10;        # Load the embedding model&#10;        model = SentenceTransformer(&quot;Shashwat13333/bge-base-en-v1.5_v4&quot;)&#10;        query_text = state.current_resource.topic&#10;        query_embedding = model.encode(query_text).tolist()&#10;&#10;        # Connect to ChromaDB&#10;        client = chromadb.PersistentClient(path=vdb_path)&#10;        lessons_col = client.get_or_create_collection(lessons_collection)&#10;        scraped_col = client.get_or_create_collection(scraped_collection)&#10;&#10;        # Query both collections&#10;        lessons_results = lessons_col.query(&#10;            query_embeddings=query_embedding,&#10;            n_results=n_results&#10;        )&#10;        scraped_results = scraped_col.query(&#10;            query_embeddings=query_embedding,&#10;            n_results=n_results&#10;        )&#10;&#10;        return {&#10;            &quot;lessons_results&quot;: lessons_results,&#10;            &quot;scraped_results&quot;: scraped_results&#10;        }&#10;    except Exception as e:&#10;        logging.error(f&quot;Error searching collections: {e}&quot;)&#10;        return None&#10;&#10;&#10;def lesson_decision_node(state: LearningState) -&gt; str:&#10;    &quot;&quot;&quot;&#10;    Decide lesson style based on curriculum metadata, topic type, and phrasing.&#10;    Returns a string indicating the lesson style.&#10;    &quot;&quot;&quot;&#10;    topic = state.current_resource.topic.lower()&#10;    unit = state.current_resource.unit.lower()&#10;    desc = state.current_resource.description.lower()&#10;&#10;    if &quot;evaluation&quot; in unit:&#10;        style = &quot;evaluation_component&quot;&#10;    elif &quot;practical&quot; in state.current_resource.topic_id or &quot;activity&quot; in topic or &quot;experiment&quot; in desc:&#10;        style = &quot;experimental&quot;&#10;    elif any(keyword in topic for keyword in [&quot;derive&quot;, &quot;calculate&quot;, &quot;problem&quot;, &quot;solve&quot;, &quot;formula&quot;]):&#10;        style = &quot;problem_solving&quot;&#10;    elif any(keyword in desc for keyword in [&quot;used in&quot;, &quot;applied in&quot;, &quot;application&quot;, &quot;real-world&quot;]):&#10;        style = &quot;application_based&quot;&#10;    elif &quot;revision&quot; in topic or &quot;summary&quot; in topic:&#10;        style = &quot;revision_summary&quot;&#10;    elif &quot;quiz&quot; in topic or state.content_type == ContentType.QUIZ:&#10;        style = &quot;interactive_quiz&quot;&#10;    elif &quot;enrich&quot; in topic or &quot;context&quot; in desc:&#10;        style = &quot;enrichment&quot;&#10;    else:&#10;        style = &quot;conceptual_focus&quot;&#10;&#10;    return style&#10;&#10;&#10;&#10;def parse_chromadb_metadata(metadata: dict) -&gt; LearningResource:&#10;    &quot;&quot;&quot;&#10;    Convert ChromaDB metadata dict to a LearningResource model.&#10;    Returns a LearningResource instance.&#10;    &quot;&quot;&quot;&#10;    return LearningResource(&#10;        subject=ResourceSubject(metadata.get('subject', 'unknown').lower()),&#10;        grade=metadata.get(&quot;grade&quot;),&#10;        unit=metadata.get(&quot;unit&quot;),&#10;        topic_id=metadata.get(&quot;topic_id&quot;),&#10;        topic=metadata.get(&quot;topic_title&quot;),&#10;        description=metadata.get(&quot;description&quot;, &quot;&quot;),&#10;        keywords=metadata.get(&quot;keywords&quot;).split(&quot;,&quot;),&#10;        hours=metadata.get(&quot;hours&quot;),&#10;        references=metadata.get(&quot;references&quot;),&#10;        elaboration=metadata.get(&quot;elaboration&quot;, &quot;&quot;)&#10;    )&#10;&#10;&#10;def blog_decision_node(state: LearningState) -&gt; str:&#10;    &quot;&quot;&quot;&#10;    Decide blog style based on topic and user grade.&#10;    Returns a string indicating the blog style.&#10;    &quot;&quot;&quot;&#10;    if &quot;importance&quot; in state.current_resource.topic:&#10;        style = &quot;motivational&quot;&#10;    elif state.user.grade &gt;= 12:&#10;        style = &quot;application_focused&quot;&#10;    else:&#10;        style = &quot;storytelling&quot;&#10;    return style&#10;&#10;def update_content_count(state: LearningState) -&gt; str:&#10;    &quot;&quot;&quot;&#10;    Check the content count in the learning state.&#10;    Returns a string indicating if an update is required.&#10;    &quot;&quot;&quot;&#10;    try:&#10;        if state.count &lt; 4:&#10;            logging.info(f&quot;Current state count: {state.count}&quot;)&#10;            return 'Update required'&#10;        else:&#10;            return 'No update required'&#10;    except Exception as e:&#10;        logging.error(f&quot;Error updating state count: {e}&quot;)&#10;        return 'No update required'" />
              <option name="updatedContent" value="import logging&#10;import chromadb&#10;&#10;logging.basicConfig(&#10;    level=logging.INFO,&#10;    format='%(asctime)s %(levelname)s [%(filename)s:%(lineno)d] %(levelname)s %(message)s',&#10;    datefmt='%Y-%m-%d %H:%M:%S'&#10;)&#10;&#10;from schemas import LearningResource, ResourceSubject, LearningState, ContentResponse, FeedBack, ContentType&#10;from db.vector_db import build_chroma_db_collection, save_scraped_data_to_vdb&#10;from sentence_transformers import SentenceTransformer&#10;&#10;&#10;def search_both_collections(state : LearningState,&#10;                            vdb_path=&quot;./local VDB/chromadb&quot;,&#10;                            lessons_collection=&quot;lessons&quot;,&#10;                            scraped_collection=&quot;scraped_data&quot;,&#10;                            n_results=1):&#10;    &quot;&quot;&quot;&#10;    Search both the lessons and scraped_data collections for the most similar items to the query.&#10;    Returns results from both collections.&#10;    &quot;&quot;&quot;&#10;    try:&#10;        if state.current_resource is None:&#10;            logging.warning(f&quot;[logical_functions.py:{search_both_collections.__code__.co_firstlineno}] WARNING No current_resource in state.&quot;)&#10;            return None&#10;&#10;&#10;        build_chroma_db_collection()&#10;        save_scraped_data_to_vdb()&#10;        # Load the embedding model&#10;        model = SentenceTransformer(&quot;Shashwat13333/bge-base-en-v1.5_v4&quot;)&#10;        query_text = state.current_resource.topic&#10;        query_embedding = model.encode(query_text).tolist()&#10;&#10;        # Connect to ChromaDB&#10;        client = chromadb.PersistentClient(path=vdb_path)&#10;        lessons_col = client.get_or_create_collection(lessons_collection)&#10;        scraped_col = client.get_or_create_collection(scraped_collection)&#10;&#10;        # Query both collections&#10;        lessons_results = lessons_col.query(&#10;            query_embeddings=query_embedding,&#10;            n_results=n_results&#10;        )&#10;        scraped_results = scraped_col.query(&#10;            query_embeddings=query_embedding,&#10;            n_results=n_results&#10;        )&#10;&#10;        logging.info(f&quot;[logical_functions.py:{search_both_collections.__code__.co_firstlineno}] INFO Queried both collections for topic '{query_text}'.&quot;)&#10;        return {&#10;            &quot;lessons_results&quot;: lessons_results,&#10;            &quot;scraped_results&quot;: scraped_results&#10;        }&#10;    except Exception as e:&#10;        logging.error(f&quot;[logical_functions.py:{search_both_collections.__code__.co_firstlineno}] ERROR Error searching collections: {e}&quot;)&#10;        return None&#10;&#10;&#10;def lesson_decision_node(state: LearningState) -&gt; str:&#10;    &quot;&quot;&quot;&#10;    Decide lesson style based on curriculum metadata, topic type, and phrasing.&#10;    Returns a string indicating the lesson style.&#10;    &quot;&quot;&quot;&#10;    topic = state.current_resource.topic.lower()&#10;    unit = state.current_resource.unit.lower()&#10;    desc = state.current_resource.description.lower()&#10;&#10;    if &quot;evaluation&quot; in unit:&#10;        style = &quot;evaluation_component&quot;&#10;    elif &quot;practical&quot; in state.current_resource.topic_id or &quot;activity&quot; in topic or &quot;experiment&quot; in desc:&#10;        style = &quot;experimental&quot;&#10;    elif any(keyword in topic for keyword in [&quot;derive&quot;, &quot;calculate&quot;, &quot;problem&quot;, &quot;solve&quot;, &quot;formula&quot;]):&#10;        style = &quot;problem_solving&quot;&#10;    elif any(keyword in desc for keyword in [&quot;used in&quot;, &quot;applied in&quot;, &quot;application&quot;, &quot;real-world&quot;]):&#10;        style = &quot;application_based&quot;&#10;    elif &quot;revision&quot; in topic or &quot;summary&quot; in topic:&#10;        style = &quot;revision_summary&quot;&#10;    elif &quot;quiz&quot; in topic or state.content_type == ContentType.QUIZ:&#10;        style = &quot;interactive_quiz&quot;&#10;    elif &quot;enrich&quot; in topic or &quot;context&quot; in desc:&#10;        style = &quot;enrichment&quot;&#10;    else:&#10;        style = &quot;conceptual_focus&quot;&#10;&#10;    return style&#10;&#10;&#10;&#10;def parse_chromadb_metadata(metadata: dict) -&gt; LearningResource:&#10;    &quot;&quot;&quot;&#10;    Convert ChromaDB metadata dict to a LearningResource model.&#10;    Returns a LearningResource instance.&#10;    &quot;&quot;&quot;&#10;    return LearningResource(&#10;        subject=ResourceSubject(metadata.get('subject', 'unknown').lower()),&#10;        grade=metadata.get(&quot;grade&quot;),&#10;        unit=metadata.get(&quot;unit&quot;),&#10;        topic_id=metadata.get(&quot;topic_id&quot;),&#10;        topic=metadata.get(&quot;topic_title&quot;),&#10;        description=metadata.get(&quot;description&quot;, &quot;&quot;),&#10;        keywords=metadata.get(&quot;keywords&quot;).split(&quot;,&quot;),&#10;        hours=metadata.get(&quot;hours&quot;),&#10;        references=metadata.get(&quot;references&quot;),&#10;        elaboration=metadata.get(&quot;elaboration&quot;, &quot;&quot;)&#10;    )&#10;&#10;&#10;def blog_decision_node(state: LearningState) -&gt; str:&#10;    &quot;&quot;&quot;&#10;    Decide blog style based on topic and user grade.&#10;    Returns a string indicating the blog style.&#10;    &quot;&quot;&quot;&#10;    if &quot;importance&quot; in state.current_resource.topic:&#10;        style = &quot;motivational&quot;&#10;    elif state.user.grade &gt;= 12:&#10;        style = &quot;application_focused&quot;&#10;    else:&#10;        style = &quot;storytelling&quot;&#10;    return style&#10;&#10;def update_content_count(state: LearningState) -&gt; str:&#10;    &quot;&quot;&quot;&#10;    Check the content count in the learning state.&#10;    Returns a string indicating if an update is required.&#10;    &quot;&quot;&quot;&#10;    try:&#10;        if state.count &lt; 4:&#10;            logging.info(f&quot;[logical_functions.py:{update_content_count.__code__.co_firstlineno}] INFO Current state count: {state.count}&quot;)&#10;            return 'Update required'&#10;        else:&#10;            logging.info(f&quot;[logical_functions.py:{update_content_count.__code__.co_firstlineno}] INFO No update required, current count: {state.count}&quot;)&#10;            return 'No update required'&#10;    except Exception as e:&#10;        logging.error(f&quot;[logical_functions.py:{update_content_count.__code__.co_firstlineno}] ERROR Error updating state count: {e}&quot;)&#10;        return 'No update required'" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/scrapper/save_to_local.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/scrapper/save_to_local.py" />
              <option name="originalContent" value="import json&#10;from typing import Union&#10;&#10;from models.external_tools_apis import serp_api_tool&#10;from schemas import LearningState&#10;&#10;def serper_api_results_parser(state: LearningState) -&gt; dict:&#10;    &quot;&quot;&quot;&#10;    Parses the results from the SerpAPI tool based on the current learning state.&#10;&#10;    Args:&#10;        state (LearningState): The current learning state containing the topic and grade.&#10;&#10;    Returns:&#10;        dict: The search results retrieved from the SerpAPI tool.&#10;    &quot;&quot;&quot;&#10;    serpapi_search_results = serp_api_tool(&#10;        query=state.current_resource.topic + 'for grade ' + str(state.current_resource.grade))&#10;    return serpapi_search_results&#10;&#10;&#10;def save_to_local(data: Union[dict, list], file_path: str):&#10;    &quot;&quot;&quot;&#10;    Saves the provided data (dict or list) to a local JSON file.&#10;&#10;    Args:&#10;        data (dict or list): The data to be saved.&#10;        file_path (str): The path where the data will be saved.&#10;&#10;    Raises:&#10;        TypeError: If the data contains unsupported types for JSON serialization.&#10;    &quot;&quot;&quot;&#10;    if not isinstance(data, (dict, list)):&#10;        raise TypeError(&quot;Data must be a dict or a list to be saved as JSON.&quot;)&#10;    with open(file_path, mode='w', encoding='utf-8') as f:&#10;        json.dump(data, f, indent=4, ensure_ascii=False)" />
              <option name="updatedContent" value="import json&#10;import logging&#10;import os&#10;from typing import Union&#10;&#10;from models.external_tools_apis import serp_api_tool&#10;from schemas import LearningState&#10;&#10;logging.basicConfig(&#10;    level=logging.INFO,&#10;    format='%(asctime)s %(levelname)s [%(filename)s:%(lineno)d] %(levelname)s %(message)s',&#10;    datefmt='%Y-%m-%d %H:%M:%S'&#10;)&#10;&#10;def serper_api_results_parser(state: LearningState) -&gt; dict:&#10;    &quot;&quot;&quot;&#10;    Parses the results from the SerpAPI tool based on the current learning state.&#10;&#10;    Args:&#10;        state (LearningState): The current learning state containing the topic and grade.&#10;&#10;    Returns:&#10;        dict: The search results retrieved from the SerpAPI tool.&#10;    &quot;&quot;&quot;&#10;    try:&#10;        serpapi_search_results = serp_api_tool(&#10;            query=state.current_resource.topic + ' for grade ' + str(state.current_resource.grade))&#10;        logging.info(f&quot;[save_to_local.py:{serper_api_results_parser.__code__.co_firstlineno}] INFO SerpAPI results parsed for topic '{state.current_resource.topic}' and grade '{state.current_resource.grade}'&quot;)&#10;        return serpapi_search_results&#10;    except Exception as e:&#10;        logging.error(f&quot;[save_to_local.py:{serper_api_results_parser.__code__.co_firstlineno}] ERROR Failed to parse SerpAPI results: {e}&quot;)&#10;        return {}&#10;&#10;def save_to_local(data: Union[dict, list], file_path: str):&#10;    &quot;&quot;&quot;&#10;    Saves the provided data (dict or list) to a local JSON file.&#10;&#10;    Args:&#10;        data (dict or list): The data to be saved.&#10;        file_path (str): The path where the data will be saved.&#10;&#10;    Raises:&#10;        TypeError: If the data contains unsupported types for JSON serialization.&#10;    &quot;&quot;&quot;&#10;    try:&#10;        if not isinstance(data, (dict, list)):&#10;            raise TypeError(&quot;Data must be a dict or a list to be saved as JSON.&quot;)&#10;        dir_name = os.path.dirname(file_path)&#10;        if dir_name:&#10;            os.makedirs(dir_name, exist_ok=True)&#10;        with open(file_path, mode='w', encoding='utf-8') as f:&#10;            json.dump(data, f, indent=4, ensure_ascii=False)&#10;        logging.info(f&quot;[save_to_local.py:{save_to_local.__code__.co_firstlineno}] INFO Data saved to {file_path}&quot;)&#10;    except Exception as e:&#10;        logging.error(f&quot;[save_to_local.py:{save_to_local.__code__.co_firstlineno}] ERROR Failed to save data to {file_path}: {e}&quot;)" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/utils.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/utils.py" />
              <option name="updatedContent" value="import os&#10;import json&#10;import logging&#10;&#10;&#10;def save_learning_state_to_json(state, file_path):&#10;    &quot;&quot;&quot;&#10;    Save the details of the LearningState object to a JSON file.&#10;    If the file does not exist, it will be created.&#10;    Args:&#10;        state: LearningState object (should have .model_dump() or .dict() method)&#10;        file_path: Path to the JSON file&#10;    &quot;&quot;&quot;&#10;    try:&#10;        # Use model_dump if available (Pydantic v2), else fallback to dict&#10;        if hasattr(state, 'model_dump'):&#10;            state_data = state.model_dump()&#10;        elif hasattr(state, 'dict'):&#10;            state_data = state.dict()&#10;        else:&#10;            raise ValueError(&quot;State object does not support serialization.&quot;)&#10;        # Ensure the directory exists&#10;        os.makedirs(os.path.dirname(file_path), exist_ok=True)&#10;        with open(file_path, 'w', encoding='utf-8') as f:&#10;            json.dump(state_data, f, indent=4, ensure_ascii=False)&#10;        logging.info(f&quot;LearningState saved to {file_path}&quot;)&#10;    except Exception as e:&#10;        logging.error(f&quot;Failed to save LearningState to {file_path}: {e}&quot;)&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>