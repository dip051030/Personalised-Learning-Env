<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/db/loader.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/db/loader.py" />
              <option name="originalContent" value="import json&#10;from pathlib import Path&#10;from typing import List, Dict, Any&#10;import logging&#10;&#10;logging.basicConfig(&#10;    level=logging.INFO,&#10;    format='%(asctime)s %(levelname)s [%(filename)s:%(lineno)d] %(levelname)s %(message)s',&#10;    datefmt='%Y-%m-%d %H:%M:%S'&#10;)&#10;&#10;DATA_DIR = Path(__file__).parent.parent / &quot;data&quot; / &quot;lessons&quot;&#10;&#10;&#10;def load_lesson_data(filename: str) -&gt; List[Dict[str, Any]]:&#10;    path = DATA_DIR / filename&#10;    logging.info(f&quot;Loading lesson data from {path}&quot;)&#10;    if not path.exists():&#10;        logging.error(f&quot;{filename} not found in {DATA_DIR}&quot;)&#10;        raise FileNotFoundError(f&quot;{filename} not found in {DATA_DIR}&quot;)&#10;&#10;    with open(path, &quot;r&quot;, encoding=&quot;utf-8&quot;) as f:&#10;        data = json.load(f)&#10;    logging.info(f&quot;Loaded {len(data)} lessons from {filename}&quot;)&#10;    return data&#10;" />
              <option name="updatedContent" value="import json&#10;from pathlib import Path&#10;from typing import List, Dict, Any&#10;import logging&#10;&#10;logging.basicConfig(&#10;    level=logging.INFO,&#10;    format='%(asctime)s %(levelname)s [%(filename)s:%(lineno)d] %(levelname)s %(message)s',&#10;    datefmt='%Y-%m-%d %H:%M:%S'&#10;)&#10;&#10;DATA_DIR = Path(__file__).parent.parent / &quot;data&quot; / &quot;lessons&quot;&#10;&#10;&#10;def load_lesson_data(filename: str) -&gt; List[Dict[str, Any]]:&#10;    &quot;&quot;&quot;&#10;    Load lesson data from a JSON file in the lessons data directory.&#10;&#10;    Args:&#10;        filename (str): The name of the lesson data file.&#10;&#10;    Returns:&#10;        List[Dict[str, Any]]: List of lesson data dictionaries.&#10;&#10;    Raises:&#10;        FileNotFoundError: If the file does not exist in the data directory.&#10;    &quot;&quot;&quot;&#10;    path = DATA_DIR / filename&#10;    logging.info(f&quot;Loading lesson data from {path}&quot;)&#10;    if not path.exists():&#10;        logging.error(f&quot;{filename} not found in {DATA_DIR}&quot;)&#10;        raise FileNotFoundError(f&quot;{filename} not found in {DATA_DIR}&quot;)&#10;&#10;    with open(path, &quot;r&quot;, encoding=&quot;utf-8&quot;) as f:&#10;        data = json.load(f)&#10;    logging.info(f&quot;Loaded {len(data)} lessons from {filename}&quot;)&#10;    return data" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/db/vector_db.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/db/vector_db.py" />
              <option name="originalContent" value="import chromadb&#10;from sentence_transformers import SentenceTransformer&#10;from db.loader import load_lesson_data&#10;import logging&#10;&#10;logging.basicConfig(&#10;    level=logging.INFO,&#10;    format='%(asctime)s %(levelname)s [%(filename)s:%(lineno)d] %(levelname)s %(message)s',&#10;    datefmt='%Y-%m-%d %H:%M:%S'&#10;)&#10;&#10;def sanitize_metadata(metadata: dict) -&gt; dict:&#10;    return {k: (&quot;,&quot;.join(v) if isinstance(v, list) else v) for k, v in metadata.items()}&#10;&#10;&#10;def build_chroma_db_collection(filename: str, collection_name: str = 'lessons'):&#10;    logging.info(f&quot;Building ChromaDB collection for {filename} with name '{collection_name}'&quot;)&#10;    lessons = load_lesson_data(filename)&#10;    model = SentenceTransformer('all-MiniLM-L6-v2')&#10;    documents = [&#10;        f&quot;{lesson.get('unit', '')} {lesson.get('topic_title', '')} {lesson.get('description', '')} {lesson.get('elaboration', '')}&quot;&#10;        for lesson in lessons&#10;    ]&#10;    logging.info(f&quot;Encoding {len(documents)} documents for embeddings&quot;)&#10;    embeddings = model.encode(documents, show_progress_bar=True).tolist()&#10;    ids = [str(lesson.get('topic_id', i)) for i, lesson in enumerate(lessons)]&#10;    metadatas = [&#10;        {&#10;            &quot;subject&quot;: lesson.get(&quot;subject&quot;),&#10;            &quot;grade&quot;: lesson.get(&quot;grade&quot;),&#10;            &quot;unit&quot;: lesson.get(&quot;unit&quot;),&#10;            &quot;topic_id&quot;: lesson.get(&quot;topic_id&quot;),&#10;            &quot;topic_title&quot;: lesson.get(&quot;topic_title&quot;),&#10;            &quot;keywords&quot;: lesson.get(&quot;keywords&quot;),&#10;            &quot;references&quot;: lesson.get(&quot;references&quot;),&#10;            &quot;hours&quot;: lesson.get(&quot;hours&quot;),&#10;            &quot;type&quot;: lesson.get(&quot;type&quot;),&#10;            'description': lesson.get('description', ''),&#10;            'elaboration': lesson.get('elaboration', '')&#10;        }&#10;        &#10;        for lesson in lessons&#10;    ]&#10;&#10;    client = chromadb.Client()&#10;    collection = client.create_collection(name=collection_name)&#10;    logging.info(f&quot;Adding documents and embeddings to ChromaDB collection '{collection_name}'&quot;)&#10;    collection.add(&#10;        documents=documents,&#10;        embeddings=embeddings,&#10;        ids=ids,&#10;        metadatas= [sanitize_metadata(metadata) for metadata in metadatas]&#10;    )&#10;    logging.info(f&quot;ChromaDB collection '{collection_name}' built successfully&quot;)&#10;    return collection, model&#10;" />
              <option name="updatedContent" value="import chromadb&#10;from sentence_transformers import SentenceTransformer&#10;from db.loader import load_lesson_data&#10;import logging&#10;&#10;logging.basicConfig(&#10;    level=logging.INFO,&#10;    format='%(asctime)s %(levelname)s [%(filename)s:%(lineno)d] %(levelname)s %(message)s',&#10;    datefmt='%Y-%m-%d %H:%M:%S'&#10;)&#10;&#10;def sanitize_metadata(metadata: dict) -&gt; dict:&#10;    &quot;&quot;&quot;&#10;    Convert list values in metadata to comma-separated strings for ChromaDB compatibility.&#10;&#10;    Args:&#10;        metadata (dict): Metadata dictionary.&#10;&#10;    Returns:&#10;        dict: Sanitized metadata dictionary.&#10;    &quot;&quot;&quot;&#10;    return {k: (&quot;,&quot;.join(v) if isinstance(v, list) else v) for k, v in metadata.items()}&#10;&#10;&#10;def build_chroma_db_collection(filename: str, collection_name: str = 'lessons'):&#10;    &quot;&quot;&quot;&#10;    Build a ChromaDB collection from lesson data and return the collection and embedding model.&#10;&#10;    Args:&#10;        filename (str): The lesson data filename.&#10;        collection_name (str): The name for the ChromaDB collection.&#10;&#10;    Returns:&#10;        tuple: (collection, embedding model)&#10;    &quot;&quot;&quot;&#10;    logging.info(f&quot;Building ChromaDB collection for {filename} with name '{collection_name}'&quot;)&#10;    lessons = load_lesson_data(filename)&#10;    model = SentenceTransformer('all-MiniLM-L6-v2')&#10;    documents = [&#10;        f&quot;{lesson.get('unit', '')} {lesson.get('topic_title', '')} {lesson.get('description', '')} {lesson.get('elaboration', '')}&quot;&#10;        for lesson in lessons&#10;    ]&#10;    logging.info(f&quot;Encoding {len(documents)} documents for embeddings&quot;)&#10;    embeddings = model.encode(documents, show_progress_bar=True).tolist()&#10;    ids = [str(lesson.get('topic_id', i)) for i, lesson in enumerate(lessons)]&#10;    metadatas = [&#10;        {&#10;            &quot;subject&quot;: lesson.get(&quot;subject&quot;),&#10;            &quot;grade&quot;: lesson.get(&quot;grade&quot;),&#10;            &quot;unit&quot;: lesson.get(&quot;unit&quot;),&#10;            &quot;topic_id&quot;: lesson.get(&quot;topic_id&quot;),&#10;            &quot;topic_title&quot;: lesson.get(&quot;topic_title&quot;),&#10;            &quot;keywords&quot;: lesson.get(&quot;keywords&quot;),&#10;            &quot;references&quot;: lesson.get(&quot;references&quot;),&#10;            &quot;hours&quot;: lesson.get(&quot;hours&quot;),&#10;            &quot;type&quot;: lesson.get(&quot;type&quot;),&#10;            'description': lesson.get('description', ''),&#10;            'elaboration': lesson.get('elaboration', '')&#10;        }&#10;        for lesson in lessons&#10;    ]&#10;&#10;    client = chromadb.Client()&#10;    collection = client.create_collection(name=collection_name)&#10;    logging.info(f&quot;Adding documents and embeddings to ChromaDB collection '{collection_name}'&quot;)&#10;    collection.add(&#10;        documents=documents,&#10;        embeddings=embeddings,&#10;        ids=ids,&#10;        metadatas= [sanitize_metadata(metadata) for metadata in metadatas]&#10;    )&#10;    logging.info(f&quot;ChromaDB collection '{collection_name}' built successfully&quot;)&#10;    return collection, model" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/keys/apis.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/keys/apis.py" />
              <option name="originalContent" value="import os&#10;import getpass&#10;from typing import Optional&#10;import logging&#10;&#10;logging.basicConfig(&#10;    level=logging.INFO,&#10;    format='%(asctime)s %(levelname)s %(message)s',&#10;    datefmt='%Y-%m-%d %H:%M:%S'&#10;)&#10;&#10;&#10;def set_env(var: str) -&gt; Optional[str]:&#10;    &quot;&quot;&quot;&#10;    Prompt for and set an environment variable if not already set.&#10;    Returns the value of the environment variable.&#10;    &quot;&quot;&quot;&#10;    if not os.environ.get(var):&#10;        logging.info(f&quot;Prompting for environment variable: {var}&quot;)&#10;        os.environ[var] = getpass.getpass(f&quot;Enter {var}: &quot;)&#10;    logging.info(f&quot;Environment variable {var} set.&quot;)&#10;    return os.environ.get(var)" />
              <option name="updatedContent" value="import os&#10;import getpass&#10;from typing import Optional&#10;import logging&#10;from dotenv import load_dotenv&#10;&#10;logging.basicConfig(&#10;    level=logging.INFO,&#10;    format='%(asctime)s %(levelname)s %(message)s',&#10;    datefmt='%Y-%m-%d %H:%M:%S'&#10;)&#10;&#10;load_dotenv()&#10;&#10;&#10;def set_env(var: str) -&gt; Optional[str]:&#10;    &quot;&quot;&quot;&#10;    Prompt for and set an environment variable if not already set.&#10;    Returns the value of the environment variable.&#10;    &quot;&quot;&quot;&#10;    if not os.environ.get(var):&#10;        logging.info(f&quot;Prompting for environment variable: {var}&quot;)&#10;        os.environ[var] = getpass.getpass(f&quot;Enter {var}: &quot;)&#10;    logging.info(f&quot;Environment variable {var} set.&quot;)&#10;    return os.environ.get(var)" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/main.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/main.py" />
              <option name="originalContent" value="import json&#10;import logging&#10;from nodes import graph_run&#10;&#10;&#10;logging.basicConfig(&#10;    level=logging.INFO,&#10;    format='%(asctime)s %(levelname)s [%(filename)s:%(lineno)d] %(levelname)s %(message)s',&#10;    datefmt='%Y-%m-%d %H:%M:%S'&#10;)&#10;&#10;user_data = {&#10;    &quot;user&quot;: {&#10;        &quot;username&quot;: &quot;anonymous&quot;,&#10;        &quot;age&quot;: 18,&#10;        &quot;grade&quot;: 19,&#10;        &quot;id&quot;: 1,&#10;        &quot;is_active&quot;: True&#10;    },&#10;    &quot;current_resource&quot;: {&#10;        &quot;subject&quot;: &quot;physics&quot;,&#10;        &quot;grade&quot;: 12,&#10;        &quot;unit&quot;: &quot;Mechanics&quot;,&#10;        &quot;topic_id&quot;: &quot;&quot;,&#10;        &quot;topic&quot;: &quot;period of pendulum&quot;,&#10;        &quot;description&quot;: &quot;&quot;,&#10;        &quot;elaboration&quot;: &quot;&quot;,&#10;        &quot;keywords&quot;: [],&#10;        &quot;hours&quot;: 1,&#10;        &quot;references&quot;: &quot;&quot;&#10;    },&#10;    &quot;progress&quot;: [],&#10;    &quot;next_action&quot;: {&quot;next_node&quot;: &quot;lesson_selection&quot;},  # &lt;-- THIS IS THE FIX&#10;    &quot;history&quot;: []&#10;}&#10;&#10;output = graph_run(user_data)&#10;logging.info(f&quot;Graph output: {output}&quot;)" />
              <option name="updatedContent" value="import json&#10;import logging&#10;from nodes import graph_run&#10;&#10;&#10;logging.basicConfig(&#10;    level=logging.INFO,&#10;    format='%(asctime)s %(levelname)s [%(filename)s:%(lineno)d] %(levelname)s %(message)s',&#10;    datefmt='%Y-%m-%d %H:%M:%S'&#10;)&#10;&#10;user_data = {&#10;    &quot;user&quot;: {&#10;        &quot;username&quot;: &quot;anonymous&quot;,&#10;        &quot;age&quot;: 18,&#10;        &quot;grade&quot;: 19,&#10;        &quot;id&quot;: 1,&#10;        &quot;is_active&quot;: True&#10;    },&#10;    &quot;current_resource&quot;: {&#10;        &quot;subject&quot;: &quot;physics&quot;,&#10;        &quot;grade&quot;: 12,&#10;        &quot;unit&quot;: &quot;Mechanics&quot;,&#10;        &quot;topic_id&quot;: &quot;&quot;,&#10;        &quot;topic&quot;: &quot;period of pendulum&quot;,&#10;        &quot;description&quot;: &quot;&quot;,&#10;        &quot;elaboration&quot;: &quot;&quot;,&#10;        &quot;keywords&quot;: [],&#10;        &quot;hours&quot;: 1,&#10;        &quot;references&quot;: &quot;&quot;&#10;    },&#10;    &quot;progress&quot;: [],&#10;    &quot;next_action&quot;: {&quot;next_node&quot;: &quot;lesson_selection&quot;},&#10;    &quot;history&quot;: []&#10;}&#10;&#10;def main():&#10;    &quot;&quot;&quot;&#10;    Entry point for running the learning graph with sample user data.&#10;    &quot;&quot;&quot;&#10;    output = graph_run(user_data)&#10;    logging.info(f&quot;Graph output: {output}&quot;)&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    main()" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/models/llm_models.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/models/llm_models.py" />
              <option name="originalContent" value="import logging&#10;logging.basicConfig(&#10;    level=logging.INFO,&#10;    format='%(asctime)s %(levelname)s [%(filename)s:%(lineno)d] %(levelname)s %(message)s',&#10;    datefmt='%Y-%m-%d %H:%M:%S'&#10;)&#10;from langchain_google_genai import ChatGoogleGenerativeAI&#10;from langchain_openai import ChatOpenAI&#10;from langchain_groq import ChatGroq&#10;from keys.apis import set_env&#10;&#10;def get_gemini_model(output_schema):&#10;    logging.info(&quot;Initializing Gemini model with structured output.&quot;)&#10;    return ChatGoogleGenerativeAI(&#10;        model='gemini-2.0-flash',&#10;        api_key=set_env('GOOGLE_API_KEY'),&#10;        temperature=1,&#10;    ).with_structured_output(output_schema)&#10;&#10;def get_groq_model():&#10;    logging.info(&quot;Initializing Groq model.&quot;)&#10;    return ChatGroq(&#10;        model='meta-llama/llama-4-scout-17b-16e-instruct',&#10;        api_key=set_env('GROQ_API_KEY'),&#10;        temperature=0.5&#10;    )&#10;&#10;def get_openai_model():&#10;    logging.info(&quot;Initializing OpenAI model.&quot;)&#10;    return ChatOpenAI(&#10;        model='gpt-4o',&#10;        temperature=0.5,&#10;        api_key=set_env('OPENAI_API_KEY')&#10;    )" />
              <option name="updatedContent" value="import logging&#10;logging.basicConfig(&#10;    level=logging.INFO,&#10;    format='%(asctime)s %(levelname)s [%(filename)s:%(lineno)d] %(levelname)s %(message)s',&#10;    datefmt='%Y-%m-%d %H:%M:%S'&#10;)&#10;from langchain_google_genai import ChatGoogleGenerativeAI&#10;from langchain_openai import ChatOpenAI&#10;from langchain_groq import ChatGroq&#10;from keys.apis import set_env&#10;&#10;def get_gemini_model(output_schema):&#10;    &quot;&quot;&quot;&#10;    Initialize and return a Gemini model with structured output for the given schema.&#10;    Args:&#10;        output_schema: The output schema for structured responses.&#10;    Returns:&#10;        ChatGoogleGenerativeAI instance with structured output.&#10;    &quot;&quot;&quot;&#10;    logging.info(&quot;Initializing Gemini model with structured output.&quot;)&#10;    return ChatGoogleGenerativeAI(&#10;        model='gemini-2.0-flash',&#10;        api_key=set_env('GOOGLE_API_KEY'),&#10;        temperature=1,&#10;    ).with_structured_output(output_schema)&#10;&#10;def get_groq_model():&#10;    &quot;&quot;&quot;&#10;    Initialize and return a Groq model for text generation.&#10;    Returns:&#10;        ChatGroq instance.&#10;    &quot;&quot;&quot;&#10;    logging.info(&quot;Initializing Groq model.&quot;)&#10;    return ChatGroq(&#10;        model='meta-llama/llama-4-scout-17b-16e-instruct',&#10;        api_key=set_env('GROQ_API_KEY'),&#10;        temperature=0.5&#10;    )&#10;&#10;def get_openai_model():&#10;    &quot;&quot;&quot;&#10;    Initialize and return an OpenAI model for text generation.&#10;    Returns:&#10;        ChatOpenAI instance.&#10;    &quot;&quot;&quot;&#10;    logging.info(&quot;Initializing OpenAI model.&quot;)&#10;    return ChatOpenAI(&#10;        model='gpt-4o',&#10;        temperature=0.5,&#10;        api_key=set_env('OPENAI_API_KEY')&#10;    )" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>