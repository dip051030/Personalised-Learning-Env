<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/db/loader.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/db/loader.py" />
              <option name="originalContent" value="import json&#10;from pathlib import Path&#10;from typing import List, Dict, Any&#10;import logging&#10;&#10;logging.basicConfig(&#10;    level=logging.INFO,&#10;    format='%(asctime)s %(levelname)s [%(filename)s:%(lineno)d] %(levelname)s %(message)s',&#10;    datefmt='%Y-%m-%d %H:%M:%S'&#10;)&#10;&#10;DATA_DIR = Path(__file__).parent.parent / &quot;data&quot; / &quot;lessons&quot;&#10;&#10;&#10;def load_lesson_data(filename: str) -&gt; List[Dict[str, Any]]:&#10;    path = DATA_DIR / filename&#10;    logging.info(f&quot;Loading lesson data from {path}&quot;)&#10;    if not path.exists():&#10;        logging.error(f&quot;{filename} not found in {DATA_DIR}&quot;)&#10;        raise FileNotFoundError(f&quot;{filename} not found in {DATA_DIR}&quot;)&#10;&#10;    with open(path, &quot;r&quot;, encoding=&quot;utf-8&quot;) as f:&#10;        data = json.load(f)&#10;    logging.info(f&quot;Loaded {len(data)} lessons from {filename}&quot;)&#10;    return data&#10;" />
              <option name="updatedContent" value="import json&#10;from pathlib import Path&#10;from typing import List, Dict, Any&#10;import logging&#10;&#10;logging.basicConfig(&#10;    level=logging.INFO,&#10;    format='%(asctime)s %(levelname)s [%(filename)s:%(lineno)d] %(levelname)s %(message)s',&#10;    datefmt='%Y-%m-%d %H:%M:%S'&#10;)&#10;&#10;DATA_DIR = Path(__file__).parent.parent / &quot;data&quot; / &quot;lessons&quot;&#10;&#10;&#10;def load_lesson_data(filename: str) -&gt; List[Dict[str, Any]]:&#10;    &quot;&quot;&quot;&#10;    Load lesson data from a JSON file in the lessons data directory.&#10;&#10;    Args:&#10;        filename (str): The name of the lesson data file.&#10;&#10;    Returns:&#10;        List[Dict[str, Any]]: List of lesson data dictionaries.&#10;&#10;    Raises:&#10;        FileNotFoundError: If the file does not exist in the data directory.&#10;    &quot;&quot;&quot;&#10;    path = DATA_DIR / filename&#10;    logging.info(f&quot;Loading lesson data from {path}&quot;)&#10;    if not path.exists():&#10;        logging.error(f&quot;{filename} not found in {DATA_DIR}&quot;)&#10;        raise FileNotFoundError(f&quot;{filename} not found in {DATA_DIR}&quot;)&#10;&#10;    with open(path, &quot;r&quot;, encoding=&quot;utf-8&quot;) as f:&#10;        data = json.load(f)&#10;    logging.info(f&quot;Loaded {len(data)} lessons from {filename}&quot;)&#10;    return data" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/db/vector_db.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/db/vector_db.py" />
              <option name="originalContent" value="import chromadb&#10;from sentence_transformers import SentenceTransformer&#10;from db.loader import load_lesson_data&#10;import logging&#10;&#10;logging.basicConfig(&#10;    level=logging.INFO,&#10;    format='%(asctime)s %(levelname)s [%(filename)s:%(lineno)d] %(levelname)s %(message)s',&#10;    datefmt='%Y-%m-%d %H:%M:%S'&#10;)&#10;&#10;def sanitize_metadata(metadata: dict) -&gt; dict:&#10;    return {k: (&quot;,&quot;.join(v) if isinstance(v, list) else v) for k, v in metadata.items()}&#10;&#10;&#10;def build_chroma_db_collection(filename: str, collection_name: str = 'lessons'):&#10;    logging.info(f&quot;Building ChromaDB collection for {filename} with name '{collection_name}'&quot;)&#10;    lessons = load_lesson_data(filename)&#10;    model = SentenceTransformer('all-MiniLM-L6-v2')&#10;    documents = [&#10;        f&quot;{lesson.get('unit', '')} {lesson.get('topic_title', '')} {lesson.get('description', '')} {lesson.get('elaboration', '')}&quot;&#10;        for lesson in lessons&#10;    ]&#10;    logging.info(f&quot;Encoding {len(documents)} documents for embeddings&quot;)&#10;    embeddings = model.encode(documents, show_progress_bar=True).tolist()&#10;    ids = [str(lesson.get('topic_id', i)) for i, lesson in enumerate(lessons)]&#10;    metadatas = [&#10;        {&#10;            &quot;subject&quot;: lesson.get(&quot;subject&quot;),&#10;            &quot;grade&quot;: lesson.get(&quot;grade&quot;),&#10;            &quot;unit&quot;: lesson.get(&quot;unit&quot;),&#10;            &quot;topic_id&quot;: lesson.get(&quot;topic_id&quot;),&#10;            &quot;topic_title&quot;: lesson.get(&quot;topic_title&quot;),&#10;            &quot;keywords&quot;: lesson.get(&quot;keywords&quot;),&#10;            &quot;references&quot;: lesson.get(&quot;references&quot;),&#10;            &quot;hours&quot;: lesson.get(&quot;hours&quot;),&#10;            &quot;type&quot;: lesson.get(&quot;type&quot;),&#10;            'description': lesson.get('description', ''),&#10;            'elaboration': lesson.get('elaboration', '')&#10;        }&#10;        &#10;        for lesson in lessons&#10;    ]&#10;&#10;    client = chromadb.Client()&#10;    collection = client.create_collection(name=collection_name)&#10;    logging.info(f&quot;Adding documents and embeddings to ChromaDB collection '{collection_name}'&quot;)&#10;    collection.add(&#10;        documents=documents,&#10;        embeddings=embeddings,&#10;        ids=ids,&#10;        metadatas= [sanitize_metadata(metadata) for metadata in metadatas]&#10;    )&#10;    logging.info(f&quot;ChromaDB collection '{collection_name}' built successfully&quot;)&#10;    return collection, model&#10;" />
              <option name="updatedContent" value="import chromadb&#10;from sentence_transformers import SentenceTransformer&#10;from db.loader import load_lesson_data&#10;import logging&#10;&#10;logging.basicConfig(&#10;    level=logging.INFO,&#10;    format='%(asctime)s %(levelname)s [%(filename)s:%(lineno)d] %(levelname)s %(message)s',&#10;    datefmt='%Y-%m-%d %H:%M:%S'&#10;)&#10;&#10;def sanitize_metadata(metadata: dict) -&gt; dict:&#10;    &quot;&quot;&quot;&#10;    Convert list values in metadata to comma-separated strings for ChromaDB compatibility.&#10;&#10;    Args:&#10;        metadata (dict): Metadata dictionary.&#10;&#10;    Returns:&#10;        dict: Sanitized metadata dictionary.&#10;    &quot;&quot;&quot;&#10;    return {k: (&quot;,&quot;.join(v) if isinstance(v, list) else v) for k, v in metadata.items()}&#10;&#10;&#10;def build_chroma_db_collection(filename: str, collection_name: str = 'lessons'):&#10;    &quot;&quot;&quot;&#10;    Build a ChromaDB collection from lesson data and return the collection and embedding model.&#10;&#10;    Args:&#10;        filename (str): The lesson data filename.&#10;        collection_name (str): The name for the ChromaDB collection.&#10;&#10;    Returns:&#10;        tuple: (collection, embedding model)&#10;    &quot;&quot;&quot;&#10;    logging.info(f&quot;Building ChromaDB collection for {filename} with name '{collection_name}'&quot;)&#10;    lessons = load_lesson_data(filename)&#10;    model = SentenceTransformer('all-MiniLM-L6-v2')&#10;    documents = [&#10;        f&quot;{lesson.get('unit', '')} {lesson.get('topic_title', '')} {lesson.get('description', '')} {lesson.get('elaboration', '')}&quot;&#10;        for lesson in lessons&#10;    ]&#10;    logging.info(f&quot;Encoding {len(documents)} documents for embeddings&quot;)&#10;    embeddings = model.encode(documents, show_progress_bar=True).tolist()&#10;    ids = [str(lesson.get('topic_id', i)) for i, lesson in enumerate(lessons)]&#10;    metadatas = [&#10;        {&#10;            &quot;subject&quot;: lesson.get(&quot;subject&quot;),&#10;            &quot;grade&quot;: lesson.get(&quot;grade&quot;),&#10;            &quot;unit&quot;: lesson.get(&quot;unit&quot;),&#10;            &quot;topic_id&quot;: lesson.get(&quot;topic_id&quot;),&#10;            &quot;topic_title&quot;: lesson.get(&quot;topic_title&quot;),&#10;            &quot;keywords&quot;: lesson.get(&quot;keywords&quot;),&#10;            &quot;references&quot;: lesson.get(&quot;references&quot;),&#10;            &quot;hours&quot;: lesson.get(&quot;hours&quot;),&#10;            &quot;type&quot;: lesson.get(&quot;type&quot;),&#10;            'description': lesson.get('description', ''),&#10;            'elaboration': lesson.get('elaboration', '')&#10;        }&#10;        for lesson in lessons&#10;    ]&#10;&#10;    client = chromadb.Client()&#10;    collection = client.create_collection(name=collection_name)&#10;    logging.info(f&quot;Adding documents and embeddings to ChromaDB collection '{collection_name}'&quot;)&#10;    collection.add(&#10;        documents=documents,&#10;        embeddings=embeddings,&#10;        ids=ids,&#10;        metadatas= [sanitize_metadata(metadata) for metadata in metadatas]&#10;    )&#10;    logging.info(f&quot;ChromaDB collection '{collection_name}' built successfully&quot;)&#10;    return collection, model" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/keys/apis.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/keys/apis.py" />
              <option name="originalContent" value="import os&#10;import getpass&#10;from typing import Optional&#10;import logging&#10;&#10;logging.basicConfig(&#10;    level=logging.INFO,&#10;    format='%(asctime)s %(levelname)s %(message)s',&#10;    datefmt='%Y-%m-%d %H:%M:%S'&#10;)&#10;&#10;&#10;def set_env(var: str) -&gt; Optional[str]:&#10;    &quot;&quot;&quot;&#10;    Prompt for and set an environment variable if not already set.&#10;    Returns the value of the environment variable.&#10;    &quot;&quot;&quot;&#10;    if not os.environ.get(var):&#10;        logging.info(f&quot;Prompting for environment variable: {var}&quot;)&#10;        os.environ[var] = getpass.getpass(f&quot;Enter {var}: &quot;)&#10;    logging.info(f&quot;Environment variable {var} set.&quot;)&#10;    return os.environ.get(var)" />
              <option name="updatedContent" value="import os&#10;import getpass&#10;from typing import Optional&#10;import logging&#10;from dotenv import load_dotenv&#10;&#10;logging.basicConfig(&#10;    level=logging.INFO,&#10;    format='%(asctime)s %(levelname)s %(message)s',&#10;    datefmt='%Y-%m-%d %H:%M:%S'&#10;)&#10;&#10;load_dotenv()&#10;&#10;&#10;def set_env(var: str) -&gt; Optional[str]:&#10;    &quot;&quot;&quot;&#10;    Prompt for and set an environment variable if not already set.&#10;    Returns the value of the environment variable.&#10;    &quot;&quot;&quot;&#10;    if not os.environ.get(var):&#10;        logging.info(f&quot;Prompting for environment variable: {var}&quot;)&#10;        os.environ[var] = getpass.getpass(f&quot;Enter {var}: &quot;)&#10;    logging.info(f&quot;Environment variable {var} set.&quot;)&#10;    return os.environ.get(var)" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/logis/logical_functions.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/logis/logical_functions.py" />
              <option name="originalContent" value="import logging&#10;&#10;logging.basicConfig(&#10;    level=logging.INFO,&#10;    format='%(asctime)s %(levelname)s [%(filename)s:%(lineno)d] %(levelname)s %(message)s',&#10;    datefmt='%Y-%m-%d %H:%M:%S'&#10;)&#10;&#10;from schemas import LearningResource, ResourceSubject, LearningState, ContentResponse, FeedBack&#10;from db.vector_db import build_chroma_db_collection&#10;from sentence_transformers import SentenceTransformer&#10;&#10;def retrieve_and_search(state: LearningState) -&gt; dict:&#10;    &quot;&quot;&quot;&#10;    Retrieve and search for resources based on the current state.&#10;    &quot;&quot;&quot;&#10;    try:&#10;        if state.current_resource is not None:&#10;            collection, model = build_chroma_db_collection('class_11_physics.json', collection_name='lessons')&#10;            query_embedding = model.encode([state.current_resource.topic]).tolist()&#10;            results = collection.query(&#10;                query_embeddings=query_embedding,&#10;                n_results=1&#10;            )&#10;            return results&#10;    except Exception as e:&#10;        logging.error(f&quot;Error retrieving and searching resources: {e}&quot;)&#10;        return None&#10;&#10;# def decision_node(state: LearningState) -&gt; str:&#10;#     &quot;&quot;&quot;&#10;#     Decide whether to generate a lesson or a blog.&#10;#     &quot;&quot;&quot;&#10;#     topic = state.current_resource.topic&#10;#     grade = int(state.user.grade)&#10;#     blog_keywords = []&#10;#     lesson_keywords = []&#10;#&#10;#     if any(kw in topic for kw in blog_keywords) and grade &gt; 10:&#10;#         return &quot;blog&quot;&#10;#     elif any(kw in topic for kw in lesson_keywords):&#10;#         return &quot;lesson&quot;&#10;#     elif grade &lt;= 10:&#10;#         return &quot;lesson&quot;&#10;#     else:&#10;#         return &quot;lesson&quot;&#10;&#10;def lesson_decision_node(state: LearningState) -&gt; str:&#10;    &quot;&quot;&quot;&#10;    Decide lesson style based on user grade and topic.&#10;    &quot;&quot;&quot;&#10;    if &quot;practice&quot; in state.current_resource.topic:&#10;        style = &quot;exercise_heavy&quot;&#10;    else:&#10;        style = &quot;general_concept&quot;&#10;    return style&#10;&#10;def parse_chromadb_metadata(metadata: dict) -&gt; LearningResource:&#10;    &quot;&quot;&quot;&#10;    Convert ChromaDB metadata dict to a LearningResource model.&#10;    &quot;&quot;&quot;&#10;    return LearningResource(&#10;    subject=ResourceSubject(metadata.get('subject', 'unknown').lower()),&#10;    grade=metadata.get(&quot;grade&quot;),&#10;    unit=metadata.get(&quot;unit&quot;),&#10;    topic_id=metadata.get(&quot;topic_id&quot;),&#10;    topic=metadata.get(&quot;topic_title&quot;),&#10;    description=metadata.get(&quot;description&quot;, &quot;&quot;),&#10;    keywords=metadata.get(&quot;keywords&quot;).split(&quot;,&quot;),&#10;    hours=metadata.get(&quot;hours&quot;),&#10;    references=metadata.get(&quot;references&quot;),&#10;    elaboration=metadata.get(&quot;elaboration&quot;, &quot;&quot;)&#10;)&#10;&#10;def blog_decision_node(state: LearningState) -&gt; str:&#10;    &quot;&quot;&quot;&#10;    Decide blog style based on topic and user grade.&#10;    &quot;&quot;&quot;&#10;    if &quot;importance&quot; in state.current_resource.topic:&#10;        style = &quot;motivational&quot;&#10;    elif state.user.grade &gt;= 12:&#10;        style = &quot;application_focused&quot;&#10;    else:&#10;        style = &quot;storytelling&quot;&#10;    return style" />
              <option name="updatedContent" value="import logging&#10;&#10;logging.basicConfig(&#10;    level=logging.INFO,&#10;    format='%(asctime)s %(levelname)s [%(filename)s:%(lineno)d] %(levelname)s %(message)s',&#10;    datefmt='%Y-%m-%d %H:%M:%S'&#10;)&#10;&#10;from schemas import LearningResource, ResourceSubject, LearningState, ContentResponse, FeedBack&#10;from db.vector_db import build_chroma_db_collection&#10;from sentence_transformers import SentenceTransformer&#10;&#10;def retrieve_and_search(state: LearningState) -&gt; dict:&#10;    &quot;&quot;&quot;&#10;    Retrieve and search for resources based on the current state.&#10;    Returns the top matching resource from the ChromaDB collection.&#10;    &quot;&quot;&quot;&#10;    try:&#10;        if state.current_resource is not None:&#10;            collection, model = build_chroma_db_collection('class_11_physics.json', collection_name='lessons')&#10;            query_embedding = model.encode([state.current_resource.topic]).tolist()&#10;            results = collection.query(&#10;                query_embeddings=query_embedding,&#10;                n_results=1&#10;            )&#10;            return results&#10;    except Exception as e:&#10;        logging.error(f&quot;Error retrieving and searching resources: {e}&quot;)&#10;        return None&#10;&#10;&#10;def lesson_decision_node(state: LearningState) -&gt; str:&#10;    &quot;&quot;&quot;&#10;    Decide lesson style based on user grade and topic.&#10;    Returns a string indicating the lesson style.&#10;    &quot;&quot;&quot;&#10;    if &quot;practice&quot; in state.current_resource.topic:&#10;        style = &quot;exercise_heavy&quot;&#10;    else:&#10;        style = &quot;general_concept&quot;&#10;    return style&#10;&#10;&#10;def parse_chromadb_metadata(metadata: dict) -&gt; LearningResource:&#10;    &quot;&quot;&quot;&#10;    Convert ChromaDB metadata dict to a LearningResource model.&#10;    Returns a LearningResource instance.&#10;    &quot;&quot;&quot;&#10;    return LearningResource(&#10;    subject=ResourceSubject(metadata.get('subject', 'unknown').lower()),&#10;    grade=metadata.get(&quot;grade&quot;),&#10;    unit=metadata.get(&quot;unit&quot;),&#10;    topic_id=metadata.get(&quot;topic_id&quot;),&#10;    topic=metadata.get(&quot;topic_title&quot;),&#10;    description=metadata.get(&quot;description&quot;, &quot;&quot;),&#10;    keywords=metadata.get(&quot;keywords&quot;).split(&quot;,&quot;),&#10;    hours=metadata.get(&quot;hours&quot;),&#10;    references=metadata.get(&quot;references&quot;),&#10;    elaboration=metadata.get(&quot;elaboration&quot;, &quot;&quot;)&#10;)&#10;&#10;&#10;def blog_decision_node(state: LearningState) -&gt; str:&#10;    &quot;&quot;&quot;&#10;    Decide blog style based on topic and user grade.&#10;    Returns a string indicating the blog style.&#10;    &quot;&quot;&quot;&#10;    if &quot;importance&quot; in state.current_resource.topic:&#10;        style = &quot;motivational&quot;&#10;    elif state.user.grade &gt;= 12:&#10;        style = &quot;application_focused&quot;&#10;    else:&#10;        style = &quot;storytelling&quot;&#10;    return style" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/main.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/main.py" />
              <option name="originalContent" value="import json&#10;import logging&#10;from nodes import graph_run&#10;&#10;&#10;logging.basicConfig(&#10;    level=logging.INFO,&#10;    format='%(asctime)s %(levelname)s [%(filename)s:%(lineno)d] %(levelname)s %(message)s',&#10;    datefmt='%Y-%m-%d %H:%M:%S'&#10;)&#10;&#10;user_data = {&#10;    &quot;user&quot;: {&#10;        &quot;username&quot;: &quot;anonymous&quot;,&#10;        &quot;age&quot;: 18,&#10;        &quot;grade&quot;: 19,&#10;        &quot;id&quot;: 1,&#10;        &quot;is_active&quot;: True&#10;    },&#10;    &quot;current_resource&quot;: {&#10;        &quot;subject&quot;: &quot;physics&quot;,&#10;        &quot;grade&quot;: 12,&#10;        &quot;unit&quot;: &quot;Mechanics&quot;,&#10;        &quot;topic_id&quot;: &quot;&quot;,&#10;        &quot;topic&quot;: &quot;period of pendulum&quot;,&#10;        &quot;description&quot;: &quot;&quot;,&#10;        &quot;elaboration&quot;: &quot;&quot;,&#10;        &quot;keywords&quot;: [],&#10;        &quot;hours&quot;: 1,&#10;        &quot;references&quot;: &quot;&quot;&#10;    },&#10;    &quot;progress&quot;: [],&#10;    &quot;next_action&quot;: {&quot;next_node&quot;: &quot;lesson_selection&quot;},  # &lt;-- THIS IS THE FIX&#10;    &quot;history&quot;: []&#10;}&#10;&#10;output = graph_run(user_data)&#10;logging.info(f&quot;Graph output: {output}&quot;)" />
              <option name="updatedContent" value="import json&#10;import logging&#10;from nodes import graph_run&#10;&#10;&#10;logging.basicConfig(&#10;    level=logging.INFO,&#10;    format='%(asctime)s %(levelname)s [%(filename)s:%(lineno)d] %(levelname)s %(message)s',&#10;    datefmt='%Y-%m-%d %H:%M:%S'&#10;)&#10;&#10;user_data = {&#10;    &quot;user&quot;: {&#10;        &quot;username&quot;: &quot;anonymous&quot;,&#10;        &quot;age&quot;: 18,&#10;        &quot;grade&quot;: 19,&#10;        &quot;id&quot;: 1,&#10;        &quot;is_active&quot;: True&#10;    },&#10;    &quot;current_resource&quot;: {&#10;        &quot;subject&quot;: &quot;physics&quot;,&#10;        &quot;grade&quot;: 12,&#10;        &quot;unit&quot;: &quot;Mechanics&quot;,&#10;        &quot;topic_id&quot;: &quot;&quot;,&#10;        &quot;topic&quot;: &quot;period of pendulum&quot;,&#10;        &quot;description&quot;: &quot;&quot;,&#10;        &quot;elaboration&quot;: &quot;&quot;,&#10;        &quot;keywords&quot;: [],&#10;        &quot;hours&quot;: 1,&#10;        &quot;references&quot;: &quot;&quot;&#10;    },&#10;    &quot;progress&quot;: [],&#10;    &quot;next_action&quot;: {&quot;next_node&quot;: &quot;lesson_selection&quot;},&#10;    &quot;history&quot;: []&#10;}&#10;&#10;def main():&#10;    &quot;&quot;&quot;&#10;    Entry point for running the learning graph with sample user data.&#10;    &quot;&quot;&quot;&#10;    output = graph_run(user_data)&#10;    logging.info(f&quot;Graph output: {output}&quot;)&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    main()" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/models/llm_models.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/models/llm_models.py" />
              <option name="originalContent" value="import logging&#10;logging.basicConfig(&#10;    level=logging.INFO,&#10;    format='%(asctime)s %(levelname)s [%(filename)s:%(lineno)d] %(levelname)s %(message)s',&#10;    datefmt='%Y-%m-%d %H:%M:%S'&#10;)&#10;from langchain_google_genai import ChatGoogleGenerativeAI&#10;from langchain_openai import ChatOpenAI&#10;from langchain_groq import ChatGroq&#10;from keys.apis import set_env&#10;&#10;def get_gemini_model(output_schema):&#10;    logging.info(&quot;Initializing Gemini model with structured output.&quot;)&#10;    return ChatGoogleGenerativeAI(&#10;        model='gemini-2.0-flash',&#10;        api_key=set_env('GOOGLE_API_KEY'),&#10;        temperature=1,&#10;    ).with_structured_output(output_schema)&#10;&#10;def get_groq_model():&#10;    logging.info(&quot;Initializing Groq model.&quot;)&#10;    return ChatGroq(&#10;        model='meta-llama/llama-4-scout-17b-16e-instruct',&#10;        api_key=set_env('GROQ_API_KEY'),&#10;        temperature=0.5&#10;    )&#10;&#10;def get_openai_model():&#10;    logging.info(&quot;Initializing OpenAI model.&quot;)&#10;    return ChatOpenAI(&#10;        model='gpt-4o',&#10;        temperature=0.5,&#10;        api_key=set_env('OPENAI_API_KEY')&#10;    )" />
              <option name="updatedContent" value="import logging&#10;logging.basicConfig(&#10;    level=logging.INFO,&#10;    format='%(asctime)s %(levelname)s [%(filename)s:%(lineno)d] %(levelname)s %(message)s',&#10;    datefmt='%Y-%m-%d %H:%M:%S'&#10;)&#10;from langchain_google_genai import ChatGoogleGenerativeAI&#10;from langchain_openai import ChatOpenAI&#10;from langchain_groq import ChatGroq&#10;from keys.apis import set_env&#10;&#10;def get_gemini_model(output_schema):&#10;    &quot;&quot;&quot;&#10;    Initialize and return a Gemini model with structured output for the given schema.&#10;    Args:&#10;        output_schema: The output schema for structured responses.&#10;    Returns:&#10;        ChatGoogleGenerativeAI instance with structured output.&#10;    &quot;&quot;&quot;&#10;    logging.info(&quot;Initializing Gemini model with structured output.&quot;)&#10;    return ChatGoogleGenerativeAI(&#10;        model='gemini-2.0-flash',&#10;        api_key=set_env('GOOGLE_API_KEY'),&#10;        temperature=1,&#10;    ).with_structured_output(output_schema)&#10;&#10;def get_groq_model():&#10;    &quot;&quot;&quot;&#10;    Initialize and return a Groq model for text generation.&#10;    Returns:&#10;        ChatGroq instance.&#10;    &quot;&quot;&quot;&#10;    logging.info(&quot;Initializing Groq model.&quot;)&#10;    return ChatGroq(&#10;        model='meta-llama/llama-4-scout-17b-16e-instruct',&#10;        api_key=set_env('GROQ_API_KEY'),&#10;        temperature=0.5&#10;    )&#10;&#10;def get_openai_model():&#10;    &quot;&quot;&quot;&#10;    Initialize and return an OpenAI model for text generation.&#10;    Returns:&#10;        ChatOpenAI instance.&#10;    &quot;&quot;&quot;&#10;    logging.info(&quot;Initializing OpenAI model.&quot;)&#10;    return ChatOpenAI(&#10;        model='gpt-4o',&#10;        temperature=0.5,&#10;        api_key=set_env('OPENAI_API_KEY')&#10;    )" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/nodes.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/nodes.py" />
              <option name="originalContent" value="from langgraph.graph import StateGraph, END&#10;&#10;from logis.logical_functions import lesson_decision_node, blog_decision_node, parse_chromadb_metadata, \&#10;    retrieve_and_search&#10;from prompts.prompts import user_summary, enriched_content, \&#10;    content_improviser, CONTENT_IMPROVISE_SYSTEM_PROMPT, route_selector, blog_generation, content_generation, \&#10;    CONTENT_FEEDBACK_SYSTEM_PROMPT&#10;from schemas import LearningState, ContentResponse, EnrichedLearningResource&#10;import json&#10;import logging&#10;&#10;logging.basicConfig(&#10;    level=logging.INFO,&#10;    format='%(asctime)s %(levelname)s [%(filename)s:%(lineno)d] %(levelname)s %(message)s',&#10;    datefmt='%Y-%m-%d %H:%M:%S'&#10;)&#10;&#10;&#10;def user_info_node(state: LearningState) -&gt; LearningState:&#10;    &quot;&quot;&quot;&#10;    Node to process and summarize user information using the user_summary prompt.&#10;    Updates the state with validated user info.&#10;    &quot;&quot;&quot;&#10;    logging.info(&quot;Entering user_info_node&quot;)&#10;    if state.user is not None:&#10;        try:&#10;            response = user_summary.invoke({&#10;                &quot;action&quot;: &quot;summarise_user&quot;,&#10;                &quot;existing_data&quot;: state.user.model_dump()&#10;            })&#10;            print(response)&#10;            user_data = response.content if hasattr(response, 'content') else response&#10;            print('hello')&#10;            state.user = state.user.model_validate(user_data if isinstance(user_data, dict) else user_data.model_dump())&#10;            logging.info(f&quot;User info processed: {state.user}&quot;)&#10;        except Exception as e:&#10;            logging.error(f&quot;Error processing user data: {e}&quot;)&#10;    return state&#10;&#10;&#10;def enrich_content(state: LearningState) -&gt; LearningState:&#10;    &quot;&quot;&quot;&#10;    Node to enrich the current learning resource using LLM enrichment.&#10;    Updates the state with an enriched resource.&#10;    &quot;&quot;&quot;&#10;    logging.info(&quot;Entering enrich_content node&quot;)&#10;    if state.current_resource is not None:&#10;        try:&#10;            retrieved_content = retrieve_and_search(state=state).get('metadatas', [])&#10;            retrieved_content = list(flatten(retrieved_content))[0]&#10;            print('RETRIEVED CONTENT', retrieved_content)&#10;            response= enriched_content.invoke({&#10;                &quot;action&quot;: &quot;content_enrichment&quot;,&#10;                &quot;current_resources_data&quot;: parse_chromadb_metadata(retrieved_content).model_dump()&#10;            })&#10;            resource_data = response.content if hasattr(response, &quot;content&quot;) else response&#10;            state.enriched_resource = EnrichedLearningResource.model_validate(resource_data)&#10;            logging.info(f&quot;Learning resource processed: {state.enriched_resource}&quot;)&#10;        except Exception as e:&#10;            logging.error(f&quot;Error processing learning resource data: {e}&quot;)&#10;    return state&#10;&#10;&#10;def route_selector_node(state: LearningState) -&gt; LearningState:&#10;    &quot;&quot;&quot;&#10;    Node to select the next route (lesson or blog) based on the enriched resource.&#10;    Updates the state with the next action.&#10;    &quot;&quot;&quot;&#10;    logging.info(&quot;Entering route_selector_node&quot;)&#10;    if state.user is not None and state.current_resource is not None:&#10;        try:&#10;            logging.info(f&quot;Selecting the route for resource: {state.current_resource}&quot;)&#10;            response = route_selector.invoke({&#10;                'current_resources' : state.enriched_resource.model_dump()&#10;            })&#10;            state.next_action = response.content if hasattr(response, &quot;content&quot;) else response&#10;            logging.info(f&quot;Route selection response: {state.next_action}&quot;)&#10;        except Exception as e:&#10;            logging.error(f&quot;Error selecting route: {e}&quot;)&#10;    return state&#10;&#10;&#10;def generate_lesson_content(state: LearningState) -&gt; LearningState:&#10;    &quot;&quot;&quot;&#10;    Node to generate lesson content using the content_generation prompt.&#10;    &quot;&quot;&quot;&#10;    logging.info(&quot;Entering generate_lesson_content node&quot;)&#10;    if state.user is not None and state.enriched_resource is not None:&#10;        try:&#10;            logical_response = lesson_decision_node(state=state)&#10;            logging.info(f&quot;Logical response for lesson generation: {logical_response}&quot;)&#10;            response = content_generation.invoke({&#10;                &quot;action&quot;: &quot;generate_lesson&quot;,&#10;                &quot;user_data&quot;: state.user.model_dump(),&#10;                &quot;resource_data&quot;: state.enriched_resource.model_dump(),&#10;                &quot;style&quot;: logical_response&#10;            })&#10;            resource_data = response.content if hasattr(response, &quot;content&quot;) else response&#10;            print(f'Generated Content: {resource_data}')&#10;            logging.info(f&quot;Lesson content has been generated!&quot;)&#10;        except Expectation as e:&#10;            logging.error(f&quot;Error generating lesson content: {e}&quot;)&#10;    return state&#10;&#10;&#10;def generate_blog_content(state: LearningState) -&gt; LearningState:&#10;    &quot;&quot;&quot;&#10;    Node to generate blog content using the blog_generation prompt.&#10;    &quot;&quot;&quot;&#10;    logging.info(&quot;Entering generate_blog_content node&quot;)&#10;    if state.user is not None and state.enriched_resource is not None:&#10;        try:&#10;            logical_response = blog_decision_node(state=state)&#10;            logging.info(f&quot;Logical response for blog generation: {logical_response}&quot;)&#10;            response = blog_generation.invoke({&#10;                &quot;action&quot;: &quot;generate_lesson&quot;,&#10;                &quot;user_data&quot;: state.user.model_dump(),&#10;                &quot;resource_data&quot;: state.enriched_resource.model_dump(),&#10;                &quot;style&quot;: logical_response&#10;            })&#10;            logging.info(f&quot;Blog content has been generated!&quot;)&#10;        except Expectation as e:&#10;            logging.error(f&quot;Error generating blog content: {e}&quot;)&#10;    return state&#10;&#10;&#10;def content_improviser_node(state: LearningState) -&gt; LearningState:&#10;    &quot;&quot;&quot;&#10;    Node to improve generated content using the content improver LLM.&#10;    Updates the state with improved content.&#10;    &quot;&quot;&quot;&#10;    logging.info(&quot;Entering content_improviser_node&quot;)&#10;    if state.content is not None:&#10;        try:&#10;            messages = [&#10;                CONTENT_IMPROVISE_SYSTEM_PROMPT,&#10;                HumanMessage(content=f&quot;&quot;&quot;&#10;Unpolished Learning Resource:&#10;{state.content.model_dump()}&#10;&quot;&quot;&quot;)&#10;            ]&#10;&#10;            response = content_improviser(messages)&#10;            generated_markdown = response.content if hasattr(response, &quot;content&quot;) else str(response)&#10;            state.content.content = ContentResponse(content=generated_markdown)&#10;            logging.info(f&quot;Improvised content has been generated!&quot;)&#10;        except Exception as e:&#10;            logging.error(f&quot;Error improvising content: {e}&quot;)&#10;    return state&#10;&#10;&#10;def collect_feedback_node(state:LearningState) -&gt; LearningState:&#10;    &quot;&quot;&quot;&#10;    Node to collect feedback on generated content.&#10;    &quot;&quot;&quot;&#10;    logging.info(&quot;Entering collect_feedback_node&quot;)&#10;    if state.content is not None:&#10;        try:&#10;            messages = [&#10;                CONTENT_FEEDBACK_SYSTEM_PROMPT,&#10;                HumanMessage(content=f&quot;&quot;&quot;&#10;Feedback:&#10;{state.content.content}&#10;&#10;&quot;&quot;&quot;)&#10;            ]&#10;            response = messages&#10;            logging.info(f&quot;Collecting feedback for content: {state.content.content}&quot;)&#10;            logging.info(f&quot;Response: {response}&quot;)&#10;        except Exception as e:&#10;            logging.error(f&quot;Error collecting feedback: {e}&quot;)&#10;    return state&#10;&#10;builder = StateGraph(LearningState)&#10;builder.add_node(&quot;user_info&quot;, user_info_node)&#10;builder.add_node(&quot;learning_resource&quot;, enrich_content)&#10;builder.add_node(&quot;route_selector&quot;, route_selector_node)&#10;builder.add_node(&quot;content_generation&quot;, generate_lesson_content)&#10;builder.add_node(&quot;blog_generation&quot;, generate_blog_content)&#10;builder.add_node(&quot;content_improviser&quot;, content_improviser_node)&#10;&#10;builder.set_entry_point(&quot;user_info&quot;)&#10;builder.add_edge(&quot;user_info&quot;, &quot;learning_resource&quot;)&#10;builder.add_edge(&quot;learning_resource&quot;, &quot;route_selector&quot;)&#10;builder.add_conditional_edges(&#10;    &quot;route_selector&quot;,&#10;    lambda state: &quot;blog_generation&quot; if state.next_action == &quot;blog&quot; else &quot;content_generation&quot;,&#10;    {&#10;        &quot;blog_generation&quot;: &quot;blog_generation&quot;,&#10;        &quot;content_generation&quot;: &quot;content_generation&quot;&#10;    }&#10;)&#10;builder.add_edge(&quot;content_generation&quot;, &quot;content_improviser&quot;)&#10;builder.add_edge(&quot;blog_generation&quot;, &quot;content_improviser&quot;)&#10;builder.add_edge(&quot;content_improviser&quot;, END)&#10;&#10;graph = builder.compile()&#10;&#10;def graph_run(user_data: dict):&#10;    return graph.invoke(LearningState.model_validate(user_data))&#10;" />
              <option name="updatedContent" value="from langgraph.graph import StateGraph, END&#10;from langchain_core.messages import HumanMessage&#10;&#10;from logis.logical_functions import lesson_decision_node, blog_decision_node, parse_chromadb_metadata, \&#10;    retrieve_and_search&#10;from prompts.prompts import user_summary, enriched_content, \&#10;    content_improviser, CONTENT_IMPROVISE_SYSTEM_PROMPT, route_selector, blog_generation, content_generation, \&#10;    CONTENT_FEEDBACK_SYSTEM_PROMPT&#10;from schemas import LearningState, ContentResponse, EnrichedLearningResource&#10;import json&#10;import logging&#10;&#10;logging.basicConfig(&#10;    level=logging.INFO,&#10;    format='%(asctime)s %(levelname)s [%(filename)s:%(lineno)d] %(levelname)s %(message)s',&#10;    datefmt='%Y-%m-%d %H:%M:%S'&#10;)&#10;&#10;&#10;def user_info_node(state: LearningState) -&gt; LearningState:&#10;    &quot;&quot;&quot;&#10;    Node to process and summarize user information using the user_summary prompt.&#10;    Updates the state with validated user info.&#10;    &quot;&quot;&quot;&#10;    logging.info(&quot;Entering user_info_node&quot;)&#10;    if state.user is not None:&#10;        try:&#10;            response = user_summary.invoke({&#10;                &quot;action&quot;: &quot;summarise_user&quot;,&#10;                &quot;existing_data&quot;: state.user.model_dump()&#10;            })&#10;            print(response)&#10;            user_data = response.content if hasattr(response, 'content') else response&#10;            print('hello')&#10;            state.user = state.user.model_validate(user_data if isinstance(user_data, dict) else user_data.model_dump())&#10;            logging.info(f&quot;User info processed: {state.user}&quot;)&#10;        except Exception as e:&#10;            logging.error(f&quot;Error processing user data: {e}&quot;)&#10;    return state&#10;&#10;&#10;def enrich_content(state: LearningState) -&gt; LearningState:&#10;    &quot;&quot;&quot;&#10;    Node to enrich the current learning resource using LLM enrichment.&#10;    Updates the state with an enriched resource.&#10;    &quot;&quot;&quot;&#10;    logging.info(&quot;Entering enrich_content node&quot;)&#10;    if state.current_resource is not None:&#10;        try:&#10;            retrieved_content = retrieve_and_search(state=state).get('metadatas', [])&#10;            retrieved_content = list(flatten(retrieved_content))[0]&#10;            print('RETRIEVED CONTENT', retrieved_content)&#10;            response= enriched_content.invoke({&#10;                &quot;action&quot;: &quot;content_enrichment&quot;,&#10;                &quot;current_resources_data&quot;: parse_chromadb_metadata(retrieved_content).model_dump()&#10;            })&#10;            resource_data = response.content if hasattr(response, &quot;content&quot;) else response&#10;            state.enriched_resource = EnrichedLearningResource.model_validate(resource_data)&#10;            logging.info(f&quot;Learning resource processed: {state.enriched_resource}&quot;)&#10;        except Exception as e:&#10;            logging.error(f&quot;Error processing learning resource data: {e}&quot;)&#10;    return state&#10;&#10;&#10;def route_selector_node(state: LearningState) -&gt; LearningState:&#10;    &quot;&quot;&quot;&#10;    Node to select the next route (lesson or blog) based on the enriched resource.&#10;    Updates the state with the next action.&#10;    &quot;&quot;&quot;&#10;    logging.info(&quot;Entering route_selector_node&quot;)&#10;    if state.user is not None and state.current_resource is not None:&#10;        try:&#10;            logging.info(f&quot;Selecting the route for resource: {state.current_resource}&quot;)&#10;            response = route_selector.invoke({&#10;                'current_resources' : state.enriched_resource.model_dump()&#10;            })&#10;            state.next_action = response.content if hasattr(response, &quot;content&quot;) else response&#10;            logging.info(f&quot;Route selection response: {state.next_action}&quot;)&#10;        except Exception as e:&#10;            logging.error(f&quot;Error selecting route: {e}&quot;)&#10;    return state&#10;&#10;&#10;def generate_lesson_content(state: LearningState) -&gt; LearningState:&#10;    &quot;&quot;&quot;&#10;    Node to generate lesson content using the content_generation prompt.&#10;    &quot;&quot;&quot;&#10;    logging.info(&quot;Entering generate_lesson_content node&quot;)&#10;    if state.user is not None and state.enriched_resource is not None:&#10;        try:&#10;            logical_response = lesson_decision_node(state=state)&#10;            logging.info(f&quot;Logical response for lesson generation: {logical_response}&quot;)&#10;            response = content_generation.invoke({&#10;                &quot;action&quot;: &quot;generate_lesson&quot;,&#10;                &quot;user_data&quot;: state.user.model_dump(),&#10;                &quot;resource_data&quot;: state.enriched_resource.model_dump(),&#10;                &quot;style&quot;: logical_response&#10;            })&#10;            resource_data = response.content if hasattr(response, &quot;content&quot;) else response&#10;            print(f'Generated Content: {resource_data}')&#10;            logging.info(f&quot;Lesson content has been generated!&quot;)&#10;        except Expectation as e:&#10;            logging.error(f&quot;Error generating lesson content: {e}&quot;)&#10;    return state&#10;&#10;&#10;def generate_blog_content(state: LearningState) -&gt; LearningState:&#10;    &quot;&quot;&quot;&#10;    Node to generate blog content using the blog_generation prompt.&#10;    &quot;&quot;&quot;&#10;    logging.info(&quot;Entering generate_blog_content node&quot;)&#10;    if state.user is not None and state.enriched_resource is not None:&#10;        try:&#10;            logical_response = blog_decision_node(state=state)&#10;            logging.info(f&quot;Logical response for blog generation: {logical_response}&quot;)&#10;            response = blog_generation.invoke({&#10;                &quot;action&quot;: &quot;generate_lesson&quot;,&#10;                &quot;user_data&quot;: state.user.model_dump(),&#10;                &quot;resource_data&quot;: state.enriched_resource.model_dump(),&#10;                &quot;style&quot;: logical_response&#10;            })&#10;            logging.info(f&quot;Blog content has been generated!&quot;)&#10;        except Expectation as e:&#10;            logging.error(f&quot;Error generating blog content: {e}&quot;)&#10;    return state&#10;&#10;&#10;def content_improviser_node(state: LearningState) -&gt; LearningState:&#10;    &quot;&quot;&quot;&#10;    Node to improve generated content using the content improver LLM.&#10;    Updates the state with improved content.&#10;    &quot;&quot;&quot;&#10;    logging.info(&quot;Entering content_improviser_node&quot;)&#10;    if state.content is not None:&#10;        try:&#10;            messages = [&#10;                CONTENT_IMPROVISE_SYSTEM_PROMPT,&#10;                HumanMessage(content=f&quot;&quot;&quot;&#10;Unpolished Learning Resource:&#10;{state.content.model_dump()}&#10;&quot;&quot;&quot;)&#10;            ]&#10;&#10;            response = content_improviser(messages)&#10;            generated_markdown = response.content if hasattr(response, &quot;content&quot;) else str(response)&#10;            state.content.content = ContentResponse(content=generated_markdown)&#10;            logging.info(f&quot;Improvised content has been generated!&quot;)&#10;        except Exception as e:&#10;            logging.error(f&quot;Error improvising content: {e}&quot;)&#10;    return state&#10;&#10;&#10;def collect_feedback_node(state:LearningState) -&gt; LearningState:&#10;    &quot;&quot;&quot;&#10;    Node to collect feedback on generated content.&#10;    &quot;&quot;&quot;&#10;    logging.info(&quot;Entering collect_feedback_node&quot;)&#10;    if state.content is not None:&#10;        try:&#10;            messages = [&#10;                CONTENT_FEEDBACK_SYSTEM_PROMPT,&#10;                HumanMessage(content=f&quot;&quot;&quot;&#10;Feedback:&#10;{state.content.content}&#10;&#10;&quot;&quot;&quot;)&#10;            ]&#10;            response = messages&#10;            logging.info(f&quot;Collecting feedback for content: {state.content.content}&quot;)&#10;            logging.info(f&quot;Response: {response}&quot;)&#10;        except Exception as e:&#10;            logging.error(f&quot;Error collecting feedback: {e}&quot;)&#10;    return state&#10;&#10;builder = StateGraph(LearningState)&#10;builder.add_node(&quot;user_info&quot;, user_info_node)&#10;builder.add_node(&quot;learning_resource&quot;, enrich_content)&#10;builder.add_node(&quot;route_selector&quot;, route_selector_node)&#10;builder.add_node(&quot;content_generation&quot;, generate_lesson_content)&#10;builder.add_node(&quot;blog_generation&quot;, generate_blog_content)&#10;builder.add_node(&quot;content_improviser&quot;, content_improviser_node)&#10;&#10;builder.set_entry_point(&quot;user_info&quot;)&#10;builder.add_edge(&quot;user_info&quot;, &quot;learning_resource&quot;)&#10;builder.add_edge(&quot;learning_resource&quot;, &quot;route_selector&quot;)&#10;builder.add_conditional_edges(&#10;    &quot;route_selector&quot;,&#10;    lambda state: &quot;blog_generation&quot; if state.next_action == &quot;blog&quot; else &quot;content_generation&quot;,&#10;    {&#10;        &quot;blog_generation&quot;: &quot;blog_generation&quot;,&#10;        &quot;content_generation&quot;: &quot;content_generation&quot;&#10;    }&#10;)&#10;builder.add_edge(&quot;content_generation&quot;, &quot;content_improviser&quot;)&#10;builder.add_edge(&quot;blog_generation&quot;, &quot;content_improviser&quot;)&#10;builder.add_edge(&quot;content_improviser&quot;, END)&#10;&#10;graph = builder.compile()&#10;&#10;def graph_run(user_data: dict):&#10;    return graph.invoke(LearningState.model_validate(user_data))" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/schemas.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/schemas.py" />
              <option name="originalContent" value="from enum import Enum&#10;from typing import Optional, Union, List, Dict&#10;from pydantic import BaseModel, Field&#10;from datetime import datetime&#10;&#10;# -----------------------------&#10;# ✅ ENUMS: Standard subject and content types&#10;# -----------------------------&#10;&#10;class ResourceSubject(str, Enum):&#10;    &quot;&quot;&quot;Academic subjects supported by the system.&quot;&quot;&quot;&#10;    PHYSICS = &quot;physics&quot;&#10;    CHEMISTRY = &quot;chemistry&quot;&#10;    MATH = &quot;math&quot;&#10;    ENGLISH = &quot;english&quot;&#10;    SCIENCE = &quot;science&quot;&#10;&#10;class ContentType(str, Enum):&#10;    &quot;&quot;&quot;Types of educational content that can be generated or tracked.&quot;&quot;&quot;&#10;    LESSON = &quot;lesson&quot;&#10;    QUIZ = &quot;quiz&quot;&#10;    PROJECT = &quot;project&quot;&#10;    PRACTICAL = &quot;practical&quot;&#10;&#10;# -----------------------------&#10;# ✅ CURRICULUM MODELS: Structure of the official curriculum&#10;# -----------------------------&#10;&#10;class Topic(BaseModel):&#10;    &quot;&quot;&quot;Represents a single topic in a curriculum unit.&quot;&quot;&quot;&#10;    topic_id: str&#10;    description: str&#10;    elaboration: str&#10;    keywords: List[str]&#10;    hours: int&#10;    references: str&#10;&#10;class Unit(BaseModel):&#10;    &quot;&quot;&quot;Groups multiple related topics under one curriculum unit.&quot;&quot;&quot;&#10;    unit: str&#10;    topics: List[Topic]&#10;&#10;class Objective(BaseModel):&#10;    &quot;&quot;&quot;Defines learning objectives for the subject.&quot;&quot;&quot;&#10;    id: int&#10;    description: str&#10;&#10;class PracticalActivity(BaseModel):&#10;    &quot;&quot;&quot;Describes practical experiments or lab work in the syllabus.&quot;&quot;&quot;&#10;    id: int&#10;    description: str&#10;    unit: str&#10;    hours: int&#10;    elaboration: str&#10;    keywords: List[str]&#10;    references: str&#10;&#10;class InternalAssessmentComponent(BaseModel):&#10;    &quot;&quot;&quot;Details components of internal evaluation (e.g., class participation).&quot;&quot;&quot;&#10;    description: str&#10;    marks: int&#10;    elaboration: str&#10;&#10;class ExternalAssessment(BaseModel):&#10;    &quot;&quot;&quot;Structure of external board-level evaluation.&quot;&quot;&quot;&#10;    weightage: int&#10;    description: str&#10;    references: str&#10;&#10;class AssessmentApproach(BaseModel):&#10;    &quot;&quot;&quot;Skills-based evaluation methods used in learning facilitation.&quot;&quot;&quot;&#10;    type: str&#10;    description: str&#10;    marks: int&#10;    elaboration: str&#10;&#10;class LearningFacilitation(BaseModel):&#10;    &quot;&quot;&quot;Teaching methods and assessment strategies recommended by the curriculum.&quot;&quot;&quot;&#10;    methods: List[str]&#10;    assessment_approach: List[AssessmentApproach]&#10;    references: str&#10;&#10;class MeasurementTool(BaseModel):&#10;    &quot;&quot;&quot;Instruments used in lab or physical measurements.&quot;&quot;&quot;&#10;    tool: str&#10;    precision: str&#10;    use: str&#10;&#10;class CurriculumMetadata(BaseModel):&#10;    &quot;&quot;&quot;Administrative details of the curriculum document.&quot;&quot;&quot;&#10;    curriculum_year: int&#10;    publisher: str&#10;    language: str&#10;    references: str&#10;&#10;class CurriculumIntro(BaseModel):&#10;    &quot;&quot;&quot;General introduction to the curriculum.&quot;&quot;&quot;&#10;    description: str&#10;&#10;class Evaluation(BaseModel):&#10;    &quot;&quot;&quot;Overall grading strategy combining internal and external components.&quot;&quot;&quot;&#10;    internal: Dict[str, Union[int, List[InternalAssessmentComponent]]]&#10;    external: ExternalAssessment&#10;&#10;class LearningCurriculum(BaseModel):&#10;    &quot;&quot;&quot;Full curriculum structure for a subject and grade.&quot;&quot;&quot;&#10;    subject: str&#10;    grade: int&#10;    credit_hours: int&#10;    subject_code: str&#10;    metadata: CurriculumMetadata&#10;    introduction: CurriculumIntro&#10;    objectives: List[Objective]&#10;    scope_and_sequence: List[Unit]&#10;    practical_activities: List[PracticalActivity]&#10;    evaluation: Evaluation&#10;    learning_facilitation: LearningFacilitation&#10;    measurement_tools: List[MeasurementTool]&#10;&#10;class CurriculumWrapper(BaseModel):&#10;    &quot;&quot;&quot;Wrapper for loading a full curriculum JSON into a single root object.&quot;&quot;&quot;&#10;    curriculum: LearningCurriculum&#10;&#10;# -----------------------------&#10;# ✅ USER + LEARNING MODELS: User data and learning session tracking&#10;# -----------------------------&#10;&#10;class UserInfo(BaseModel):&#10;    &quot;&quot;&quot;User profile information.&quot;&quot;&quot;&#10;    username: str&#10;    age: Union[int, float, str]&#10;    grade: Optional[Union[int, float, str]] = None&#10;    id: Union[str, int]&#10;    is_active: bool = True&#10;    user_info: Optional[str] = Field(default='', description=&quot;Summarised User Info. &quot;)&#10;&#10;    class Config:&#10;        from_attributes = True&#10;&#10;class LearningResource(BaseModel):&#10;    &quot;&quot;&quot;A flattened topic extracted from curriculum and prepared for delivery or search.&quot;&quot;&quot;&#10;    subject: ResourceSubject&#10;    grade: int&#10;    unit: str&#10;    topic_id: str&#10;    topic: str&#10;    description: str&#10;    elaboration: Optional[str] = None&#10;    keywords: List[str] = []&#10;    hours: int&#10;    references: str&#10;&#10;    class Config:&#10;        from_attributes = True&#10;&#10;class UserProgress(BaseModel):&#10;    &quot;&quot;&quot;Tracks the user's progress on a specific topic or activity.&quot;&quot;&quot;&#10;    id: int&#10;    user_id: Union[str, int]&#10;    resource: LearningResource&#10;    completed: bool = False&#10;    completion_date: Optional[datetime] = None&#10;    score: Optional[float] = None&#10;&#10;    class Config:&#10;        from_attributes = True&#10;&#10;class ContentResponse(BaseModel):&#10;    &quot;&quot;&quot;Output generated by the LLM (lessons, quizzes, etc).&quot;&quot;&quot;&#10;    content: str&#10;&#10;    class Config:&#10;        from_attributes = True&#10;&#10;class HistoryEntry(BaseModel):&#10;    &quot;&quot;&quot;Logs a single user action (e.g., viewed content).&quot;&quot;&quot;&#10;    user_id: Union[str, int]&#10;    resource: LearningResource&#10;    timestamp: datetime&#10;    action: str&#10;&#10;    class Config:&#10;        from_attributes = True&#10;&#10;class EnrichedLearningResource(BaseModel):&#10;    &quot;&quot;&quot;An enriched version of a learning resource with LLM-generated summaries.&quot;&quot;&quot;&#10;    subject: ResourceSubject&#10;    grade: int&#10;    unit: str&#10;    topic_id: str&#10;    topic: str&#10;    description: str&#10;    elaboration: Optional[str] = None&#10;    keywords: List[str] = []&#10;    hours: int&#10;    references: str&#10;&#10;class FeedBack(BaseModel):&#10;    &quot;&quot;&quot;User feedback on generated content.&quot;&quot;&quot;&#10;    resource: Optional[ContentResponse] = ''&#10;    rating: int = 1 # 1-5 scale&#10;    comments: Optional[str] = None&#10;&#10;    class Config:&#10;        from_attributes = True&#10;&#10;class RouteSelector(BaseModel):&#10;    next_node: str&#10;&#10;class LearningState(BaseModel):&#10;    &quot;&quot;&quot;Tracks the session state of a user's learning journey across all nodes.&quot;&quot;&quot;&#10;    user: UserInfo&#10;    # resources: Optional[List[LearningResource]] = []&#10;    current_resource: Optional[LearningResource] = None&#10;    enriched_resource: Optional[EnrichedLearningResource] = None&#10;    progress: List[UserProgress] = []&#10;    topic_data: Optional[Dict] = None&#10;    related_examples: Optional[List[str]] = None&#10;    content_type: ContentType = ContentType.LESSON&#10;    content: Optional[ContentResponse] = None&#10;    next_action: Optional[RouteSelector] = Field(default=&quot;lesson_selection&quot;, description=&quot;Should return lesson_selection or blog_selection&quot;)&#10;    history: List[HistoryEntry] = []&#10;    # feedback: Optional[FeedBack] = {}&#10;&#10;    class Config:&#10;        from_attributes = True&#10;&#10;" />
              <option name="updatedContent" value="from enum import Enum&#10;from typing import Optional, Union, List, Dict&#10;from pydantic import BaseModel, Field&#10;from datetime import datetime&#10;&#10;# -----------------------------&#10;# ✅ ENUMS: Standard subject and content types&#10;# -----------------------------&#10;&#10;class ResourceSubject(str, Enum):&#10;    &quot;&quot;&quot;Academic subjects supported by the system.&quot;&quot;&quot;&#10;    PHYSICS = &quot;physics&quot;&#10;    CHEMISTRY = &quot;chemistry&quot;&#10;    MATH = &quot;math&quot;&#10;    ENGLISH = &quot;english&quot;&#10;    SCIENCE = &quot;science&quot;&#10;&#10;class ContentType(str, Enum):&#10;    &quot;&quot;&quot;Types of educational content that can be generated or tracked.&quot;&quot;&quot;&#10;    LESSON = &quot;lesson&quot;&#10;    QUIZ = &quot;quiz&quot;&#10;    PROJECT = &quot;project&quot;&#10;    PRACTICAL = &quot;practical&quot;&#10;&#10;# -----------------------------&#10;# ✅ CURRICULUM MODELS: Structure of the official curriculum&#10;# -----------------------------&#10;&#10;class Topic(BaseModel):&#10;    &quot;&quot;&quot;Represents a single topic in a curriculum unit.&quot;&quot;&quot;&#10;    topic_id: str&#10;    description: str&#10;    elaboration: str&#10;    keywords: List[str]&#10;    hours: int&#10;    references: str&#10;&#10;class Unit(BaseModel):&#10;    &quot;&quot;&quot;Groups multiple related topics under one curriculum unit.&quot;&quot;&quot;&#10;    unit: str&#10;    topics: List[Topic]&#10;&#10;class Objective(BaseModel):&#10;    &quot;&quot;&quot;Defines learning objectives for the subject.&quot;&quot;&quot;&#10;    id: int&#10;    description: str&#10;&#10;class PracticalActivity(BaseModel):&#10;    &quot;&quot;&quot;Describes practical experiments or lab work in the syllabus.&quot;&quot;&quot;&#10;    id: int&#10;    description: str&#10;    unit: str&#10;    hours: int&#10;    elaboration: str&#10;    keywords: List[str]&#10;    references: str&#10;&#10;class InternalAssessmentComponent(BaseModel):&#10;    &quot;&quot;&quot;Details components of internal evaluation (e.g., class participation).&quot;&quot;&quot;&#10;    description: str&#10;    marks: int&#10;    elaboration: str&#10;&#10;class ExternalAssessment(BaseModel):&#10;    &quot;&quot;&quot;Structure of external board-level evaluation.&quot;&quot;&quot;&#10;    weightage: int&#10;    description: str&#10;    references: str&#10;&#10;class AssessmentApproach(BaseModel):&#10;    &quot;&quot;&quot;Skills-based evaluation methods used in learning facilitation.&quot;&quot;&quot;&#10;    type: str&#10;    description: str&#10;    marks: int&#10;    elaboration: str&#10;&#10;class LearningFacilitation(BaseModel):&#10;    &quot;&quot;&quot;Teaching methods and assessment strategies recommended by the curriculum.&quot;&quot;&quot;&#10;    methods: List[str]&#10;    assessment_approach: List[AssessmentApproach]&#10;    references: str&#10;&#10;class MeasurementTool(BaseModel):&#10;    &quot;&quot;&quot;Instruments used in lab or physical measurements.&quot;&quot;&quot;&#10;    tool: str&#10;    precision: str&#10;    use: str&#10;&#10;class CurriculumMetadata(BaseModel):&#10;    &quot;&quot;&quot;Administrative details of the curriculum document.&quot;&quot;&quot;&#10;    curriculum_year: int&#10;    publisher: str&#10;    language: str&#10;    references: str&#10;&#10;class CurriculumIntro(BaseModel):&#10;    &quot;&quot;&quot;General introduction to the curriculum.&quot;&quot;&quot;&#10;    description: str&#10;&#10;class Evaluation(BaseModel):&#10;    &quot;&quot;&quot;Overall grading strategy combining internal and external components.&quot;&quot;&quot;&#10;    internal: Dict[str, Union[int, List[InternalAssessmentComponent]]]&#10;    external: ExternalAssessment&#10;&#10;class LearningCurriculum(BaseModel):&#10;    &quot;&quot;&quot;Full curriculum structure for a subject and grade.&quot;&quot;&quot;&#10;    subject: str&#10;    grade: int&#10;    credit_hours: int&#10;    subject_code: str&#10;    metadata: CurriculumMetadata&#10;    introduction: CurriculumIntro&#10;    objectives: List[Objective]&#10;    scope_and_sequence: List[Unit]&#10;    practical_activities: List[PracticalActivity]&#10;    evaluation: Evaluation&#10;    learning_facilitation: LearningFacilitation&#10;    measurement_tools: List[MeasurementTool]&#10;&#10;class CurriculumWrapper(BaseModel):&#10;    &quot;&quot;&quot;Wrapper for loading a full curriculum JSON into a single root object.&quot;&quot;&quot;&#10;    curriculum: LearningCurriculum&#10;&#10;# -----------------------------&#10;# ✅ USER + LEARNING MODELS: User data and learning session tracking&#10;# -----------------------------&#10;&#10;class UserInfo(BaseModel):&#10;    &quot;&quot;&quot;User profile information.&quot;&quot;&quot;&#10;    username: str&#10;    age: Union[int, float, str]&#10;    grade: Optional[Union[int, float, str]] = None&#10;    id: Union[str, int]&#10;    is_active: bool = True&#10;    user_info: Optional[str] = Field(default='', description=&quot;Summarised User Info. &quot;)&#10;&#10;    class Config:&#10;        from_attributes = True&#10;&#10;class LearningResource(BaseModel):&#10;    &quot;&quot;&quot;A flattened topic extracted from curriculum and prepared for delivery or search.&quot;&quot;&quot;&#10;    subject: ResourceSubject&#10;    grade: int&#10;    unit: str&#10;    topic_id: str&#10;    topic: str&#10;    description: str&#10;    elaboration: Optional[str] = None&#10;    keywords: List[str] = []&#10;    hours: int&#10;    references: str&#10;&#10;    class Config:&#10;        from_attributes = True&#10;&#10;class UserProgress(BaseModel):&#10;    &quot;&quot;&quot;Tracks the user's progress on a specific topic or activity.&quot;&quot;&quot;&#10;    id: int&#10;    user_id: Union[str, int]&#10;    resource: LearningResource&#10;    completed: bool = False&#10;    completion_date: Optional[datetime] = None&#10;    score: Optional[float] = None&#10;&#10;    class Config:&#10;        from_attributes = True&#10;&#10;class ContentResponse(BaseModel):&#10;    &quot;&quot;&quot;Output generated by the LLM (lessons, quizzes, etc).&quot;&quot;&quot;&#10;    content: str&#10;&#10;    class Config:&#10;        from_attributes = True&#10;&#10;class HistoryEntry(BaseModel):&#10;    &quot;&quot;&quot;Logs a single user action (e.g., viewed content).&quot;&quot;&quot;&#10;    user_id: Union[str, int]&#10;    resource: LearningResource&#10;    timestamp: datetime&#10;    action: str&#10;&#10;    class Config:&#10;        from_attributes = True&#10;&#10;class EnrichedLearningResource(BaseModel):&#10;    &quot;&quot;&quot;An enriched version of a learning resource with LLM-generated summaries.&quot;&quot;&quot;&#10;    subject: ResourceSubject&#10;    grade: int&#10;    unit: str&#10;    topic_id: str&#10;    topic: str&#10;    description: str&#10;    elaboration: Optional[str] = None&#10;    keywords: List[str] = []&#10;    hours: int&#10;    references: str&#10;&#10;class FeedBack(BaseModel):&#10;    &quot;&quot;&quot;User feedback on generated content.&quot;&quot;&quot;&#10;    resource: Optional[ContentResponse] = ''&#10;    rating: int = 1 # 1-5 scale&#10;    comments: Optional[str] = None&#10;&#10;    class Config:&#10;        from_attributes = True&#10;&#10;class RouteSelector(BaseModel):&#10;    next_node: str&#10;&#10;class LearningState(BaseModel):&#10;    &quot;&quot;&quot;Tracks the session state of a user's learning journey across all nodes.&quot;&quot;&quot;&#10;    user: UserInfo&#10;    # resources: Optional[List[LearningResource]] = []&#10;    current_resource: Optional[LearningResource] = None&#10;    enriched_resource: Optional[EnrichedLearningResource] = None&#10;    progress: List[UserProgress] = []&#10;    topic_data: Optional[Dict] = None&#10;    related_examples: Optional[List[str]] = None&#10;    content_type: ContentType = ContentType.LESSON&#10;    content: Optional[ContentResponse] = None&#10;    next_action: Optional[RouteSelector] = Field(default=&quot;lesson_selection&quot;, description=&quot;Should return lesson_selection or blog_selection&quot;)&#10;    history: List[HistoryEntry] = []&#10;    # feedback: Optional[FeedBack] = {}&#10;&#10;    class Config:&#10;        from_attributes = True" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>