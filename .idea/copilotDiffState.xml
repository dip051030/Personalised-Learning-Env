<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/logis/logical_functions.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/logis/logical_functions.py" />
              <option name="originalContent" value="import logging&#10;&#10;logging.basicConfig(&#10;    level=logging.INFO,&#10;    format='%(asctime)s %(levelname)s [%(filename)s:%(lineno)d] %(levelname)s %(message)s',&#10;    datefmt='%Y-%m-%d %H:%M:%S'&#10;)&#10;&#10;from schemas import LearningResource, ResourceSubject, LearningState, ContentResponse, FeedBack&#10;from db.vector_db import build_chroma_db_collection&#10;from sentence_transformers import SentenceTransformer&#10;&#10;def retrieve_and_search(state: LearningState) -&gt; dict:&#10;    &quot;&quot;&quot;&#10;    Retrieve and search for resources based on the current state.&#10;    Returns the top matching resource from the ChromaDB collection.&#10;    &quot;&quot;&quot;&#10;    try:&#10;        if state.current_resource is not None:&#10;            collection, model = build_chroma_db_collection('class_11_physics.json', collection_name='lessons')&#10;            query_embedding = model.encode([state.current_resource.topic]).tolist()&#10;            results = collection.query(&#10;                query_embeddings=query_embedding,&#10;                n_results=1&#10;            )&#10;            return results&#10;    except Exception as e:&#10;        logging.error(f&quot;Error retrieving and searching resources: {e}&quot;)&#10;        return None&#10;&#10;&#10;def lesson_decision_node(state: LearningState) -&gt; str:&#10;    &quot;&quot;&quot;&#10;    Decide lesson style based on user grade and topic.&#10;    Returns a string indicating the lesson style.&#10;    &quot;&quot;&quot;&#10;    if &quot;practice&quot; in state.current_resource.topic:&#10;        style = &quot;exercise_heavy&quot;&#10;    else:&#10;        style = &quot;general_concept&quot;&#10;    return style&#10;&#10;&#10;def parse_chromadb_metadata(metadata: dict) -&gt; LearningResource:&#10;    &quot;&quot;&quot;&#10;    Convert ChromaDB metadata dict to a LearningResource model.&#10;    Returns a LearningResource instance.&#10;    &quot;&quot;&quot;&#10;    return LearningResource(&#10;        subject=ResourceSubject(metadata.get('subject', 'unknown').lower()),&#10;        grade=metadata.get(&quot;grade&quot;),&#10;        unit=metadata.get(&quot;unit&quot;),&#10;        topic_id=metadata.get(&quot;topic_id&quot;),&#10;        topic=metadata.get(&quot;topic_title&quot;),&#10;        description=metadata.get(&quot;description&quot;, &quot;&quot;),&#10;        keywords=metadata.get(&quot;keywords&quot;).split(&quot;,&quot;),&#10;        hours=metadata.get(&quot;hours&quot;),&#10;        references=metadata.get(&quot;references&quot;),&#10;        elaboration=metadata.get(&quot;elaboration&quot;, &quot;&quot;)&#10;    )&#10;&#10;&#10;def blog_decision_node(state: LearningState) -&gt; str:&#10;    &quot;&quot;&quot;&#10;    Decide blog style based on topic and user grade.&#10;    Returns a string indicating the blog style.&#10;    &quot;&quot;&quot;&#10;    if &quot;importance&quot; in state.current_resource.topic:&#10;        style = &quot;motivational&quot;&#10;    elif state.user.grade &gt;= 12:&#10;        style = &quot;application_focused&quot;&#10;    else:&#10;        style = &quot;storytelling&quot;&#10;    return style&#10;&#10;def update_content_count(state: LearningState) -&gt; str:&#10;    &quot;&quot;&quot;&#10;    Check the content count in the learning state.&#10;    Returns a string indicating if an update is required.&#10;    &quot;&quot;&quot;&#10;    try:&#10;        if state.count &lt; 2:&#10;            logging.info(f&quot;Current state count: {state.count}&quot;)&#10;            return 'Update required'&#10;        else:&#10;            return 'No update required'&#10;    except Exception as e:&#10;        logging.error(f&quot;Error updating state count: {e}&quot;)&#10;        return 'No update required'" />
              <option name="updatedContent" value="import logging&#10;&#10;logging.basicConfig(&#10;    level=logging.INFO,&#10;    format='%(asctime)s %(levelname)s [%(filename)s:%(lineno)d] %(levelname)s %(message)s',&#10;    datefmt='%Y-%m-%d %H:%M:%S'&#10;)&#10;&#10;from schemas import LearningResource, ResourceSubject, LearningState, ContentResponse, FeedBack&#10;from db.vector_db import build_chroma_db_collection&#10;from sentence_transformers import SentenceTransformer&#10;&#10;def retrieve_and_search(state: LearningState) -&gt; dict | None:&#10;    &quot;&quot;&quot;&#10;    Retrieve and search for resources based on the current state.&#10;    Returns the top matching resource from the ChromaDB collection or None.&#10;    &quot;&quot;&quot;&#10;    try:&#10;        if state.current_resource is not None:&#10;            collection, model = build_chroma_db_collection('class_11_physics.json', collection_name='lessons')&#10;            query_embedding = model.encode([state.current_resource.topic]).tolist()&#10;            results = collection.query(&#10;                query_embeddings=query_embedding,&#10;                n_results=1&#10;            )&#10;            return results&#10;    except Exception as e:&#10;        logging.error(f&quot;Error retrieving and searching resources: {e}&quot;)&#10;        return None&#10;&#10;&#10;def lesson_decision_node(state: LearningState) -&gt; str:&#10;    &quot;&quot;&quot;&#10;    Decide lesson style based on user grade and topic.&#10;    Returns a string indicating the lesson style.&#10;    &quot;&quot;&quot;&#10;    if &quot;practice&quot; in state.current_resource.topic:&#10;        style = &quot;exercise_heavy&quot;&#10;    else:&#10;        style = &quot;general_concept&quot;&#10;    return style&#10;&#10;&#10;def parse_chromadb_metadata(metadata: dict) -&gt; LearningResource:&#10;    &quot;&quot;&quot;&#10;    Convert ChromaDB metadata dict to a LearningResource model.&#10;    Returns a LearningResource instance.&#10;    &quot;&quot;&quot;&#10;    # keywords is already a list, so don't split&#10;    return LearningResource(&#10;        subject=ResourceSubject(metadata.get('subject', 'unknown').lower()),&#10;        grade=metadata.get(&quot;grade&quot;),&#10;        unit=metadata.get(&quot;unit&quot;),&#10;        topic_id=metadata.get(&quot;topic_id&quot;),&#10;        topic=metadata.get(&quot;topic_title&quot;),&#10;        description=metadata.get(&quot;description&quot;, &quot;&quot;),&#10;        keywords=metadata.get(&quot;keywords&quot;, []),&#10;        hours=metadata.get(&quot;hours&quot;),&#10;        references=metadata.get(&quot;references&quot;),&#10;        elaboration=metadata.get(&quot;elaboration&quot;, &quot;&quot;)&#10;    )&#10;&#10;&#10;def blog_decision_node(state: LearningState) -&gt; str:&#10;    &quot;&quot;&quot;&#10;    Decide blog style based on topic and user grade.&#10;    Returns a string indicating the blog style.&#10;    &quot;&quot;&quot;&#10;    if &quot;importance&quot; in state.current_resource.topic:&#10;        style = &quot;motivational&quot;&#10;    elif state.user.grade &gt;= 12:&#10;        style = &quot;application_focused&quot;&#10;    else:&#10;        style = &quot;storytelling&quot;&#10;    return style&#10;&#10;def update_content_count(state: LearningState) -&gt; str:&#10;    &quot;&quot;&quot;&#10;    Check the content count in the learning state.&#10;    Returns a string indicating if an update is required.&#10;    &quot;&quot;&quot;&#10;    try:&#10;        if state.count &lt; 2:&#10;            logging.info(f&quot;Current state count: {state.count}&quot;)&#10;            return 'Update required'&#10;        else:&#10;            return 'No update required'&#10;    except Exception as e:&#10;        logging.error(f&quot;Error updating state count: {e}&quot;)&#10;        return 'No update required'" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/nodes.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/nodes.py" />
              <option name="originalContent" value="from more_itertools import flatten&#10;from langgraph.graph import StateGraph, END&#10;from langchain_core.messages import HumanMessage&#10;&#10;from logis.logical_functions import lesson_decision_node, blog_decision_node, parse_chromadb_metadata, \&#10;    retrieve_and_search, update_content_count&#10;from prompts.prompts import user_summary, enriched_content, \&#10;    content_improviser, CONTENT_IMPROVISE_SYSTEM_PROMPT, route_selector, blog_generation, content_generation, \&#10;    CONTENT_FEEDBACK_SYSTEM_PROMPT, prompt_content_improviser, prompt_feedback, content_feedback, gap_finder&#10;from schemas import LearningState, ContentResponse, EnrichedLearningResource, FeedBack, RouteSelector&#10;import json&#10;import logging&#10;import os&#10;&#10;logging.basicConfig(&#10;    level=logging.INFO,&#10;    format='%(asctime)s %(levelname)s [%(filename)s:%(lineno)d] %(levelname)s %(message)s',&#10;    datefmt='%Y-%m-%d %H:%M:%S'&#10;)&#10;&#10;&#10;def user_info_node(state: LearningState) -&gt; LearningState:&#10;    &quot;&quot;&quot;&#10;    Node to process and summarize user information using the user_summary prompt.&#10;    Updates the state with validated user info.&#10;    &quot;&quot;&quot;&#10;    logging.info(&quot;Entering user_info_node&quot;)&#10;    if state.user is not None:&#10;        try:&#10;            response = user_summary.invoke({&#10;                &quot;action&quot;: &quot;summarise_user&quot;,&#10;                &quot;existing_data&quot;: state.user.model_dump()&#10;            })&#10;            print(response)&#10;            user_data = response.content if hasattr(response, 'content') else response&#10;            print('hello')&#10;            state.user = state.user.model_validate(user_data if isinstance(user_data, dict) else user_data.model_dump())&#10;            logging.info(f&quot;User info processed: {state.user}&quot;)&#10;        except Exception as e:&#10;            logging.error(f&quot;Error processing user data: {e}&quot;)&#10;    return state&#10;&#10;&#10;def enrich_content(state: LearningState) -&gt; LearningState:&#10;    &quot;&quot;&quot;&#10;    Node to enrich the current learning resource using LLM enrichment.&#10;    Updates the state with an enriched resource.&#10;    &quot;&quot;&quot;&#10;    logging.info(&quot;Entering enrich_content node&quot;)&#10;    if state.current_resource is not None:&#10;        try:&#10;            retrieved = retrieve_and_search(state=state)&#10;            if not retrieved:&#10;                logging.error(&quot;No content retrieved from vector DB.&quot;)&#10;                return state&#10;            retrieved_content = retrieved.get('metadatas', [])&#10;            if not retrieved_content:&#10;                logging.error(&quot;No metadatas found in retrieved content.&quot;)&#10;                return state&#10;            retrieved_content = list(flatten(retrieved_content))[0]&#10;            print('RETRIEVED CONTENT', retrieved_content)&#10;            response = enriched_content.invoke({&#10;                &quot;action&quot;: &quot;content_enrichment&quot;,&#10;                &quot;current_resources_data&quot;: parse_chromadb_metadata(retrieved_content).model_dump()&#10;            })&#10;            resource_data = response.content if hasattr(response, &quot;content&quot;) else response&#10;            state.enriched_resource = EnrichedLearningResource.model_validate(resource_data)&#10;            logging.info(f&quot;Learning resource processed: {state.enriched_resource}&quot;)&#10;        except Exception as e:&#10;            logging.error(f&quot;Error processing learning resource data: {e}&quot;)&#10;    return state&#10;&#10;&#10;def route_selector_node(state: LearningState) -&gt; LearningState:&#10;    &quot;&quot;&quot;&#10;    Node to select the next route (lesson or blog) based on the enriched resource.&#10;    Updates the state with the next action.&#10;    &quot;&quot;&quot;&#10;    logging.info(&quot;Entering route_selector_node&quot;)&#10;    if state.user is not None and state.current_resource is not None:&#10;        try:&#10;            logging.info(f&quot;Selecting the route for resource: {state.current_resource}&quot;)&#10;            response = route_selector.invoke({&#10;                'current_resources': state.enriched_resource.model_dump()&#10;            })&#10;            # Set next_action as a RouteSelector model&#10;            next_action_str = response.content if hasattr(response, &quot;content&quot;) else response&#10;            state.next_action = RouteSelector(next_node=next_action_str)&#10;            logging.info(f&quot;Route selection response: {state.next_action}&quot;)&#10;        except Exception as e:&#10;            logging.error(f&quot;Error selecting route: {e}&quot;)&#10;    return state&#10;&#10;&#10;def generate_lesson_content(state: LearningState) -&gt; LearningState:&#10;    &quot;&quot;&quot;&#10;    Node to generate lesson content using the content_generation prompt.&#10;    &quot;&quot;&quot;&#10;    logging.info(&quot;Entering generate_lesson_content node&quot;)&#10;    if state.user is not None and state.enriched_resource is not None:&#10;        try:&#10;            logical_response = lesson_decision_node(state=state)&#10;            logging.info(f&quot;Logical response for lesson generation: {logical_response}&quot;)&#10;            response = content_generation.invoke({&#10;                &quot;action&quot;: &quot;generate_lesson&quot;,&#10;                &quot;user_data&quot;: state.user.model_dump(),&#10;                &quot;resource_data&quot;: state.enriched_resource.model_dump(),&#10;                &quot;style&quot;: logical_response&#10;            })&#10;            resource_data = response.content if hasattr(response, &quot;content&quot;) else response&#10;            # print(f'Generated Content: {resource_data}')&#10;            state.content = ContentResponse(content = resource_data)&#10;            logging.info(f&quot;Lesson content has been generated!&quot;)&#10;            print(f'Generated Content: {state.content}')&#10;        except Exception as e:&#10;            logging.error(f&quot;Error generating lesson content: {e}&quot;)&#10;    return state&#10;&#10;&#10;def generate_blog_content(state: LearningState) -&gt; LearningState:&#10;    &quot;&quot;&quot;&#10;    Node to generate blog content using the blog_generation prompt.&#10;    &quot;&quot;&quot;&#10;    logging.info(&quot;Entering generate_blog_content node&quot;)&#10;    if state.user is not None and state.enriched_resource is not None:&#10;        try:&#10;            logical_response = blog_decision_node(state=state)&#10;            logging.info(f&quot;Logical response for blog generation: {logical_response}&quot;)&#10;            response = blog_generation.invoke({&#10;                &quot;action&quot;: &quot;generate_lesson&quot;,&#10;                &quot;user_data&quot;: state.user.model_dump(),&#10;                &quot;resource_data&quot;: state.enriched_resource.model_dump(),&#10;                &quot;style&quot;: logical_response&#10;            })&#10;            resource_data = response.content if hasattr(response, &quot;content&quot;) else response&#10;            state.content = ContentResponse(content=resource_data)&#10;            logging.info(f&quot;Blog content has been generated!&quot;)&#10;        except Exception as e:&#10;            logging.error(f&quot;Error generating blog content: {e}&quot;)&#10;    return state&#10;&#10;&#10;def content_improviser_node(state: LearningState) -&gt; LearningState:&#10;    &quot;&quot;&quot;&#10;    Node to improve generated content using the content improver LLM.&#10;    Uses the latest feedback (including gaps) to improve the content.&#10;    Updates the state with improved content.&#10;    &quot;&quot;&quot;&#10;    logging.info(&quot;Entering content_improviser_node&quot;)&#10;    if state.content is not None and state.feedback is not None:&#10;        try:&#10;            messages = [&#10;                prompt_content_improviser,&#10;                HumanMessage(content=f&quot;&quot;&quot;&#10;Unpolished Learning Resource:&#10;{state.content.model_dump()}&#10;&#10;Please improve the content by making it more engaging, informative, and suitable for the target audience.&#10;&#10;Feedback (including gaps):&#10;{state.feedback.model_dump()}&#10;&#10;&quot;&quot;&quot;)&#10;            ]&#10;            response = content_improviser.invoke(messages)&#10;            improved_content = response.content if hasattr(response, &quot;content&quot;) else str(response)&#10;            # Update state.content with the newly generated improvised content&#10;            state.content = ContentResponse(content=improved_content)&#10;            logging.info(f&quot;Improvised content has been generated and updated in state.content!&quot;)&#10;        except Exception as e:&#10;            logging.error(f&quot;Error improvising content: {e}&quot;)&#10;    return state&#10;&#10;&#10;def collect_feedback_node(state:LearningState) -&gt; LearningState:&#10;    &quot;&quot;&quot;&#10;    Node to collect feedback on generated content.&#10;    &quot;&quot;&quot;&#10;    logging.info(&quot;Entering collect_feedback_node&quot;)&#10;    feedback_data = None  # Ensure variable is always defined&#10;    if state.content is not None:&#10;        try:&#10;            logging.info(f&quot;Collecting feedback for content&quot;)&#10;&#10;            messages = [&#10;                prompt_feedback,&#10;                HumanMessage(content=f&quot;&quot;&quot;&#10;Unpolished Learning Resource:&#10;{state.content.content}&#10;                &#10;Feedback:&#10;{state.feedback}&#10;&#10;&quot;&quot;&quot;)&#10;            ]&#10;            response = content_feedback.invoke(messages)&#10;            logging.info(f&quot;Feedback has been collected!&quot;)&#10;            feedback_data = response.content if hasattr(response, &quot;content&quot;) else response&#10;            feedback_data = json.loads(feedback_data) if isinstance(feedback_data, str) else feedback_data&#10;            print('FEEDBACK DATA:', type(feedback_data))&#10;            state.feedback = FeedBack.model_validate(feedback_data)&#10;            print('State FEEDBACK: ', state.feedback)&#10;            logging.info(f&quot;Feedback processed!&quot;)&#10;        except Exception as e:&#10;            logging.error(f&quot;Error collecting feedback: {e}&quot;)&#10;            print('FEEDBACK DATA:', feedback_data)&#10;    return state&#10;&#10;&#10;def find_content_gap_node(state: LearningState) -&gt; LearningState:&#10;    &quot;&quot;&quot;&#10;    Node to find content gaps based on user feedback.&#10;    Updates the feedback in state with new gaps for the next improvise node.&#10;    &quot;&quot;&quot;&#10;    logging.info(&quot;Entering find_content_gap_node&quot;)&#10;    if state.feedback is not None and state.content is not None:&#10;        logging.info(f&quot;Finding content gaps based on feedback: {state.feedback}&quot;)&#10;        data = gap_finder.invoke({&#10;            'content': state.content.content if hasattr(state.content, 'content') else str(state.content),&#10;            'feedback': state.feedback.model_dump(),&#10;        })&#10;        response = data.content if hasattr(data, &quot;content&quot;) else data&#10;        print(f'Gaps : {response}')&#10;        # Update feedback with new gaps for the next improvise node&#10;        state.feedback = FeedBack.model_validate(json.loads(response) if isinstance(response, str) else response)&#10;        logging.info(f&quot;Feedback received and updated: {state.feedback}&quot;)&#10;    return state&#10;&#10;def update_state(state: LearningState) -&gt; LearningState:&#10;    try:&#10;        if not hasattr(state, &quot;count&quot;):&#10;            state.count = 0&#10;        response = update_content_count(state)&#10;        if response == 'Update required':&#10;            state.count += 1&#10;            logging.info(f&quot;State updated: {state.count}&quot;)&#10;        else:&#10;            logging.info(f&quot;No update required, current count: {state.count}&quot;)&#10;    except Exception as e:&#10;        logging.error(f&quot;Error updating state: {e}&quot;)&#10;    return state&#10;&#10;&#10;def save_learning_state_to_json(state, file_path):&#10;    &quot;&quot;&quot;&#10;    Save the details of the LearningState object to a JSON file.&#10;    If the file does not exist, it will be created.&#10;    Args:&#10;        state: LearningState object (should have .model_dump() or .dict() method)&#10;        file_path: Path to the JSON file&#10;    &quot;&quot;&quot;&#10;    try:&#10;        # Use model_dump if available (Pydantic v2), else fallback to dict&#10;        if hasattr(state, 'model_dump'):&#10;            state_data = state.model_dump()&#10;        elif hasattr(state, 'dict'):&#10;            state_data = state.dict()&#10;        else:&#10;            raise ValueError(&quot;State object does not support serialization.&quot;)&#10;        # Ensure the directory exists&#10;        os.makedirs(os.path.dirname(file_path), exist_ok=True)&#10;        with open(file_path, 'w', encoding='utf-8') as f:&#10;            json.dump(state_data, f, indent=4, ensure_ascii=False)&#10;        logging.info(f&quot;LearningState saved to {file_path}&quot;)&#10;    except Exception as e:&#10;        logging.error(f&quot;Failed to save LearningState to {file_path}: {e}&quot;)&#10;&#10;&#10;builder = StateGraph(LearningState)&#10;builder.add_node(&quot;user_info&quot;, user_info_node)&#10;builder.add_node(&quot;learning_resource&quot;, enrich_content)&#10;builder.add_node(&quot;route_selector&quot;, route_selector_node)&#10;builder.add_node(&quot;content_generation&quot;, generate_lesson_content)&#10;builder.add_node(&quot;blog_generation&quot;, generate_blog_content)&#10;builder.add_node(&quot;content_improviser&quot;, content_improviser_node)&#10;builder.add_node(&quot;collect_feedback&quot;, collect_feedback_node)&#10;builder.add_node(&quot;find_content_gap&quot;, find_content_gap_node)&#10;builder.add_node(&quot;update_state&quot;, update_state)&#10;&#10;builder.set_entry_point(&quot;user_info&quot;)&#10;builder.add_edge(&quot;user_info&quot;, &quot;learning_resource&quot;)&#10;builder.add_edge(&quot;learning_resource&quot;, &quot;route_selector&quot;)&#10;builder.add_conditional_edges(&#10;    &quot;route_selector&quot;,&#10;    lambda state: (&#10;        state.next_action.next_node&#10;        if hasattr(state.next_action, &quot;next_node&quot;) and state.next_action.next_node in [&quot;blog_generation&quot;, &quot;content_generation&quot;]&#10;        else &quot;content_generation&quot;  # Default branch if next_action is missing or invalid&#10;    ),&#10;    {&#10;        &quot;blog_generation&quot;: &quot;blog_generation&quot;,&#10;        &quot;content_generation&quot;: &quot;content_generation&quot;&#10;    }&#10;)&#10;builder.add_edge(&quot;content_generation&quot;, &quot;content_improviser&quot;)&#10;builder.add_edge(&quot;blog_generation&quot;, &quot;content_improviser&quot;)&#10;builder.add_edge(&quot;content_improviser&quot;, 'collect_feedback')&#10;builder.add_edge(&quot;collect_feedback&quot;, &quot;find_content_gap&quot;)&#10;builder.add_edge(&quot;find_content_gap&quot;, &quot;update_state&quot;)&#10;builder.add_conditional_edges(&#10;    &quot;update_state&quot;,&#10;    lambda state: &quot;content_improviser&quot; if getattr(state, &quot;count&quot;, 0) &lt; 2 else &quot;END&quot;,&#10;    {&#10;        &quot;content_improviser&quot;: &quot;content_improviser&quot;,&#10;        &quot;END&quot;: END&#10;    }&#10;)&#10;&#10;graph = builder.compile()&#10;&#10;def graph_run(user_data: dict):&#10;    return graph.invoke(LearningState.model_validate(user_data))&#10;" />
              <option name="updatedContent" value="from more_itertools import flatten&#10;from langgraph.graph import StateGraph, END&#10;from langchain_core.messages import HumanMessage&#10;&#10;from logis.logical_functions import lesson_decision_node, blog_decision_node, parse_chromadb_metadata, \&#10;    retrieve_and_search, update_content_count&#10;from prompts.prompts import user_summary, enriched_content, \&#10;    content_improviser, CONTENT_IMPROVISE_SYSTEM_PROMPT, route_selector, blog_generation, content_generation, \&#10;    CONTENT_FEEDBACK_SYSTEM_PROMPT, prompt_content_improviser, prompt_feedback, content_feedback, gap_finder&#10;from schemas import LearningState, ContentResponse, EnrichedLearningResource, FeedBack, RouteSelector&#10;import json&#10;import logging&#10;import os&#10;&#10;logging.basicConfig(&#10;    level=logging.INFO,&#10;    format='%(asctime)s %(levelname)s [%(filename)s:%(lineno)d] %(levelname)s %(message)s',&#10;    datefmt='%Y-%m-%d %H:%M:%S'&#10;)&#10;&#10;&#10;def user_info_node(state: LearningState) -&gt; LearningState:&#10;    &quot;&quot;&quot;&#10;    Node to process and summarize user information using the user_summary prompt.&#10;    Updates the state with validated user info.&#10;    &quot;&quot;&quot;&#10;    logging.info(&quot;Entering user_info_node&quot;)&#10;    if state.user is not None:&#10;        try:&#10;            response = user_summary.invoke({&#10;                &quot;action&quot;: &quot;summarise_user&quot;,&#10;                &quot;existing_data&quot;: state.user.model_dump()&#10;            })&#10;            print(response)&#10;            user_data = response.content if hasattr(response, 'content') else response&#10;            print('hello')&#10;            state.user = state.user.model_validate(user_data if isinstance(user_data, dict) else user_data.model_dump())&#10;            logging.info(f&quot;User info processed: {state.user}&quot;)&#10;        except Exception as e:&#10;            logging.error(f&quot;Error processing user data: {e}&quot;)&#10;    return state&#10;&#10;&#10;def enrich_content(state: LearningState) -&gt; LearningState:&#10;    &quot;&quot;&quot;&#10;    Node to enrich the current learning resource using LLM enrichment.&#10;    Updates the state with an enriched resource.&#10;    &quot;&quot;&quot;&#10;    logging.info(&quot;Entering enrich_content node&quot;)&#10;    if state.current_resource is not None:&#10;        try:&#10;            retrieved = retrieve_and_search(state=state)&#10;            if not retrieved:&#10;                logging.error(&quot;No content retrieved from vector DB.&quot;)&#10;                return state&#10;            retrieved_content = retrieved.get('metadatas', [])&#10;            if not retrieved_content:&#10;                logging.error(&quot;No metadatas found in retrieved content.&quot;)&#10;                return state&#10;            retrieved_content = list(flatten(retrieved_content))[0]&#10;            print('RETRIEVED CONTENT', retrieved_content)&#10;            response = enriched_content.invoke({&#10;                &quot;action&quot;: &quot;content_enrichment&quot;,&#10;                &quot;current_resources_data&quot;: parse_chromadb_metadata(retrieved_content).model_dump()&#10;            })&#10;            resource_data = response.content if hasattr(response, &quot;content&quot;) else response&#10;            state.enriched_resource = EnrichedLearningResource.model_validate(resource_data)&#10;            logging.info(f&quot;Learning resource processed: {state.enriched_resource}&quot;)&#10;        except Exception as e:&#10;            logging.error(f&quot;Error processing learning resource data: {e}&quot;)&#10;    return state&#10;&#10;&#10;def route_selector_node(state: LearningState) -&gt; LearningState:&#10;    &quot;&quot;&quot;&#10;    Node to select the next route (lesson or blog) based on the enriched resource.&#10;    Updates the state with the next action.&#10;    &quot;&quot;&quot;&#10;    logging.info(&quot;Entering route_selector_node&quot;)&#10;    if state.user is not None and state.current_resource is not None:&#10;        try:&#10;            logging.info(f&quot;Selecting the route for resource: {state.current_resource}&quot;)&#10;            response = route_selector.invoke({&#10;                'current_resources': state.enriched_resource.model_dump()&#10;            })&#10;            # Set next_action as a RouteSelector model&#10;            next_action_str = response.content if hasattr(response, &quot;content&quot;) else response&#10;            state.next_action = RouteSelector(next_node=next_action_str)&#10;            logging.info(f&quot;Route selection response: {state.next_action}&quot;)&#10;        except Exception as e:&#10;            logging.error(f&quot;Error selecting route: {e}&quot;)&#10;    return state&#10;&#10;&#10;def generate_lesson_content(state: LearningState) -&gt; LearningState:&#10;    &quot;&quot;&quot;&#10;    Node to generate lesson content using the content_generation prompt.&#10;    &quot;&quot;&quot;&#10;    logging.info(&quot;Entering generate_lesson_content node&quot;)&#10;    if state.user is not None and state.enriched_resource is not None:&#10;        try:&#10;            logical_response = lesson_decision_node(state=state)&#10;            logging.info(f&quot;Logical response for lesson generation: {logical_response}&quot;)&#10;            response = content_generation.invoke({&#10;                &quot;action&quot;: &quot;generate_lesson&quot;,&#10;                &quot;user_data&quot;: state.user.model_dump(),&#10;                &quot;resource_data&quot;: state.enriched_resource.model_dump(),&#10;                &quot;style&quot;: logical_response&#10;            })&#10;            resource_data = response.content if hasattr(response, &quot;content&quot;) else response&#10;            # print(f'Generated Content: {resource_data}')&#10;            state.content = ContentResponse(content = resource_data)&#10;            logging.info(f&quot;Lesson content has been generated!&quot;)&#10;            print(f'Generated Content: {state.content}')&#10;        except Exception as e:&#10;            logging.error(f&quot;Error generating lesson content: {e}&quot;)&#10;    return state&#10;&#10;&#10;def generate_blog_content(state: LearningState) -&gt; LearningState:&#10;    &quot;&quot;&quot;&#10;    Node to generate blog content using the blog_generation prompt.&#10;    &quot;&quot;&quot;&#10;    logging.info(&quot;Entering generate_blog_content node&quot;)&#10;    if state.user is not None and state.enriched_resource is not None:&#10;        try:&#10;            logical_response = blog_decision_node(state=state)&#10;            logging.info(f&quot;Logical response for blog generation: {logical_response}&quot;)&#10;            response = blog_generation.invoke({&#10;                &quot;action&quot;: &quot;generate_lesson&quot;,&#10;                &quot;user_data&quot;: state.user.model_dump(),&#10;                &quot;resource_data&quot;: state.enriched_resource.model_dump(),&#10;                &quot;style&quot;: logical_response&#10;            })&#10;            resource_data = response.content if hasattr(response, &quot;content&quot;) else response&#10;            state.content = ContentResponse(content=resource_data)&#10;            logging.info(f&quot;Blog content has been generated!&quot;)&#10;        except Exception as e:&#10;            logging.error(f&quot;Error generating blog content: {e}&quot;)&#10;    return state&#10;&#10;&#10;def content_improviser_node(state: LearningState) -&gt; LearningState:&#10;    &quot;&quot;&quot;&#10;    Node to improve generated content using the content improver LLM.&#10;    Uses the latest feedback (including gaps) to improve the content.&#10;    Updates the state with improved content.&#10;    &quot;&quot;&quot;&#10;    logging.info(&quot;Entering content_improviser_node&quot;)&#10;    if state.content is not None and state.feedback is not None:&#10;        try:&#10;            messages = [&#10;                prompt_content_improviser,&#10;                HumanMessage(content=f&quot;&quot;&quot;&#10;Unpolished Learning Resource:&#10;{state.content.model_dump()}&#10;&#10;Please improve the content by making it more engaging, informative, and suitable for the target audience.&#10;&#10;Feedback (including gaps):&#10;{state.feedback.model_dump()}&#10;&#10;&quot;&quot;&quot;)&#10;            ]&#10;            response = content_improviser.invoke(messages)&#10;            improved_content = response.content if hasattr(response, &quot;content&quot;) else str(response)&#10;            # Update state.content with the newly generated improvised content&#10;            state.content = ContentResponse(content=improved_content)&#10;            logging.info(f&quot;Improvised content has been generated and updated in state.content!&quot;)&#10;        except Exception as e:&#10;            logging.error(f&quot;Error improvising content: {e}&quot;)&#10;    return state&#10;&#10;&#10;def collect_feedback_node(state:LearningState) -&gt; LearningState:&#10;    &quot;&quot;&quot;&#10;    Node to collect feedback on generated content.&#10;    &quot;&quot;&quot;&#10;    logging.info(&quot;Entering collect_feedback_node&quot;)&#10;    feedback_data = None  # Ensure variable is always defined&#10;    if state.content is not None:&#10;        try:&#10;            logging.info(f&quot;Collecting feedback for content&quot;)&#10;&#10;            messages = [&#10;                prompt_feedback,&#10;                HumanMessage(content=f&quot;&quot;&quot;&#10;Unpolished Learning Resource:&#10;{state.content.content}&#10;                &#10;Feedback:&#10;{state.feedback}&#10;&#10;&quot;&quot;&quot;)&#10;            ]&#10;            response = content_feedback.invoke(messages)&#10;            logging.info(f&quot;Feedback has been collected!&quot;)&#10;            feedback_data = response.content if hasattr(response, &quot;content&quot;) else response&#10;            feedback_data = json.loads(feedback_data) if isinstance(feedback_data, str) else feedback_data&#10;            print('FEEDBACK DATA:', type(feedback_data))&#10;            state.feedback = FeedBack.model_validate(feedback_data)&#10;            print('State FEEDBACK: ', state.feedback)&#10;            logging.info(f&quot;Feedback processed!&quot;)&#10;        except Exception as e:&#10;            logging.error(f&quot;Error collecting feedback: {e}&quot;)&#10;            print('FEEDBACK DATA:', feedback_data)&#10;    return state&#10;&#10;&#10;def find_content_gap_node(state: LearningState) -&gt; LearningState:&#10;    &quot;&quot;&quot;&#10;    Node to find content gaps based on user feedback.&#10;    Updates the feedback in state with new gaps for the next improvise node.&#10;    &quot;&quot;&quot;&#10;    logging.info(&quot;Entering find_content_gap_node&quot;)&#10;    if state.feedback is not None and state.content is not None:&#10;        logging.info(f&quot;Finding content gaps based on feedback: {state.feedback}&quot;)&#10;        data = gap_finder.invoke({&#10;            'content': state.content.content if hasattr(state.content, 'content') else str(state.content),&#10;            'feedback': state.feedback.model_dump(),&#10;        })&#10;        response = data.content if hasattr(data, &quot;content&quot;) else data&#10;        print(f'Gaps : {response}')&#10;        # Update feedback with new gaps for the next improvise node&#10;        updated_feedback = FeedBack.model_validate(json.loads(response) if isinstance(response, str) else response)&#10;        state.feedback = updated_feedback&#10;        logging.info(f&quot;Feedback received and updated: {state.feedback}&quot;)&#10;    return state&#10;&#10;def update_state(state: LearningState) -&gt; LearningState:&#10;    try:&#10;        if not hasattr(state, &quot;count&quot;):&#10;            state.count = 0&#10;        response = update_content_count(state)&#10;        if response == 'Update required':&#10;            state.count += 1&#10;            logging.info(f&quot;State updated: {state.count}&quot;)&#10;        else:&#10;            logging.info(f&quot;No update required, current count: {state.count}&quot;)&#10;    except Exception as e:&#10;        logging.error(f&quot;Error updating state: {e}&quot;)&#10;    return state&#10;&#10;&#10;def save_learning_state_to_json(state, file_path):&#10;    &quot;&quot;&quot;&#10;    Save the details of the LearningState object to a JSON file.&#10;    If the file does not exist, it will be created.&#10;    Args:&#10;        state: LearningState object (should have .model_dump() or .dict() method)&#10;        file_path: Path to the JSON file&#10;    &quot;&quot;&quot;&#10;    try:&#10;        # Use model_dump if available (Pydantic v2), else fallback to dict&#10;        if hasattr(state, 'model_dump'):&#10;            state_data = state.model_dump()&#10;        elif hasattr(state, 'dict'):&#10;            state_data = state.dict()&#10;        else:&#10;            raise ValueError(&quot;State object does not support serialization.&quot;)&#10;        # Ensure the directory exists&#10;        os.makedirs(os.path.dirname(file_path), exist_ok=True)&#10;        with open(file_path, 'w', encoding='utf-8') as f:&#10;            json.dump(state_data, f, indent=4, ensure_ascii=False)&#10;        logging.info(f&quot;LearningState saved to {file_path}&quot;)&#10;    except Exception as e:&#10;        logging.error(f&quot;Failed to save LearningState to {file_path}: {e}&quot;)&#10;&#10;&#10;builder = StateGraph(LearningState)&#10;builder.add_node(&quot;user_info&quot;, user_info_node)&#10;builder.add_node(&quot;learning_resource&quot;, enrich_content)&#10;builder.add_node(&quot;route_selector&quot;, route_selector_node)&#10;builder.add_node(&quot;content_generation&quot;, generate_lesson_content)&#10;builder.add_node(&quot;blog_generation&quot;, generate_blog_content)&#10;builder.add_node(&quot;content_improviser&quot;, content_improviser_node)&#10;builder.add_node(&quot;collect_feedback&quot;, collect_feedback_node)&#10;builder.add_node(&quot;find_content_gap&quot;, find_content_gap_node)&#10;builder.add_node(&quot;update_state&quot;, update_state)&#10;&#10;builder.set_entry_point(&quot;user_info&quot;)&#10;builder.add_edge(&quot;user_info&quot;, &quot;learning_resource&quot;)&#10;builder.add_edge(&quot;learning_resource&quot;, &quot;route_selector&quot;)&#10;builder.add_conditional_edges(&#10;    &quot;route_selector&quot;,&#10;    lambda state: (&#10;        state.next_action.next_node&#10;        if hasattr(state.next_action, &quot;next_node&quot;) and state.next_action.next_node in [&quot;blog_generation&quot;, &quot;content_generation&quot;]&#10;        else &quot;content_generation&quot;  # Default branch if next_action is missing or invalid&#10;    ),&#10;    {&#10;        &quot;blog_generation&quot;: &quot;blog_generation&quot;,&#10;        &quot;content_generation&quot;: &quot;content_generation&quot;&#10;    }&#10;)&#10;builder.add_edge(&quot;content_generation&quot;, &quot;content_improviser&quot;)&#10;builder.add_edge(&quot;blog_generation&quot;, &quot;content_improviser&quot;)&#10;builder.add_edge(&quot;content_improviser&quot;, 'collect_feedback')&#10;builder.add_edge(&quot;collect_feedback&quot;, &quot;find_content_gap&quot;)&#10;builder.add_edge(&quot;find_content_gap&quot;, &quot;update_state&quot;)&#10;builder.add_conditional_edges(&#10;    &quot;update_state&quot;,&#10;    lambda state: &quot;content_improviser&quot; if getattr(state, &quot;count&quot;, 0) &lt; 2 else &quot;END&quot;,&#10;    {&#10;        &quot;content_improviser&quot;: &quot;content_improviser&quot;,&#10;        &quot;END&quot;: END&#10;    }&#10;)&#10;&#10;graph = builder.compile()&#10;&#10;def graph_run(user_data: dict):&#10;    return graph.invoke(LearningState.model_validate(user_data))" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/utils.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/utils.py" />
              <option name="updatedContent" value="import os&#10;import json&#10;import logging&#10;&#10;&#10;def save_learning_state_to_json(state, file_path):&#10;    &quot;&quot;&quot;&#10;    Save the details of the LearningState object to a JSON file.&#10;    If the file does not exist, it will be created.&#10;    Args:&#10;        state: LearningState object (should have .model_dump() or .dict() method)&#10;        file_path: Path to the JSON file&#10;    &quot;&quot;&quot;&#10;    try:&#10;        # Use model_dump if available (Pydantic v2), else fallback to dict&#10;        if hasattr(state, 'model_dump'):&#10;            state_data = state.model_dump()&#10;        elif hasattr(state, 'dict'):&#10;            state_data = state.dict()&#10;        else:&#10;            raise ValueError(&quot;State object does not support serialization.&quot;)&#10;        # Ensure the directory exists&#10;        os.makedirs(os.path.dirname(file_path), exist_ok=True)&#10;        with open(file_path, 'w', encoding='utf-8') as f:&#10;            json.dump(state_data, f, indent=4, ensure_ascii=False)&#10;        logging.info(f&quot;LearningState saved to {file_path}&quot;)&#10;    except Exception as e:&#10;        logging.error(f&quot;Failed to save LearningState to {file_path}: {e}&quot;)&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/utils/utils.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/utils/utils.py" />
              <option name="originalContent" value="import os&#10;import json&#10;import logging&#10;&#10;def save_learning_state_to_json(state, file_path):&#10;    &quot;&quot;&quot;&#10;    Save the details of the LearningState object to a JSON file.&#10;    If the file does not exist, it will be created.&#10;    Args:&#10;        state: LearningState object (should have .model_dump() or .dict() method)&#10;        file_path: Path to the JSON file&#10;    &quot;&quot;&quot;&#10;    try:&#10;        # Use model_dump if available (Pydantic v2), else fallback to dict&#10;        if hasattr(state, 'model_dump'):&#10;            state_data = state.model_dump()&#10;        elif hasattr(state, 'dict'):&#10;            state_data = state.dict()&#10;        else:&#10;            raise ValueError(&quot;State object does not support serialization.&quot;)&#10;        # Ensure the directory exists&#10;        os.makedirs(os.path.dirname(file_path), exist_ok=True)&#10;        with open(file_path, 'w', encoding='utf-8') as f:&#10;            json.dump(state_data, f, indent=4, ensure_ascii=False)&#10;        logging.info(f&quot;LearningState saved to {file_path}&quot;)&#10;    except Exception as e:&#10;        logging.error(f&quot;Failed to save LearningState to {file_path}: {e}&quot;)&#10;&#10;" />
              <option name="updatedContent" value="import os&#10;import json&#10;import logging&#10;&#10;def save_learning_state_to_json(state, file_path):&#10;    &quot;&quot;&quot;&#10;    Save the details of the LearningState object or dict to a JSON file.&#10;    If the file does not exist, it will be created.&#10;    Args:&#10;        state: LearningState object (should have .model_dump() or .dict() method) or dict&#10;        file_path: Path to the JSON file&#10;    &quot;&quot;&quot;&#10;    try:&#10;        if hasattr(state, 'model_dump'):&#10;            state_data = state.model_dump()&#10;        elif hasattr(state, 'dict'):&#10;            state_data = state.dict()&#10;        elif isinstance(state, dict):&#10;            state_data = state&#10;        else:&#10;            raise ValueError(&quot;State object does not support serialization.&quot;)&#10;        os.makedirs(os.path.dirname(file_path), exist_ok=True)&#10;        with open(file_path, 'w', encoding='utf-8') as f:&#10;            json.dump(state_data, f, indent=4, ensure_ascii=False)&#10;        logging.info(f&quot;LearningState saved to {file_path}&quot;)&#10;    except Exception as e:&#10;        logging.error(f&quot;Failed to save LearningState to {file_path}: {e}&quot;)" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>